{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载基本库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import ffmyh\n",
    "import time\n",
    "import math\n",
    "# from sklearn import ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import log_loss\n",
    "import xgboost\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "import sklearn\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "%run FeatureProcess.py\n",
    "# from fastFM.datasets import make_user_item_regression\n",
    "# from fastFM import als\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df_org = pd.read_table('../../round1_ijcai_18_train_20180301.txt',sep=' ')\n",
    "test_df_org = pd.read_table('../../round1_ijcai_18_test_a_20180301.txt',sep=' ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df_org.columns\n",
    "\n",
    "train_df = train_df_org.copy().set_index(\"context_id\")\n",
    "test_df = test_df_org.copy().set_index(\"context_id\")\n",
    "\n",
    "test_df[\"is_trade\"] = -1\n",
    "train_df_prev = train_df.append(test_df)\n",
    "# print len(train_df)\n",
    "# print train_df[[\"is_trade\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2018-09-18': 0, '2018-09-19': 1, '2018-09-20': 2, '2018-09-21': 3, '2018-09-22': 4, '2018-09-23': 5, '2018-09-24': 6, '2018-09-25': 7}\n"
     ]
    }
   ],
   "source": [
    "# 时间处理: 分离天, 星期几, 上中下午/晚上, 小时数\n",
    "# date最终不使用，直接用day(第 0 - 7 天)\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def extract_date(x):\n",
    "    d = datetime.fromtimestamp(x)\n",
    "    return d.strftime(\"%Y-%m-%d\")\n",
    "def extract_time(x):\n",
    "    d = datetime.fromtimestamp(x)\n",
    "    return d.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "def extract_weekday(x):\n",
    "    d = datetime.fromtimestamp(x)\n",
    "    return d.weekday()\n",
    "def extract_hour(x):\n",
    "    d = datetime.fromtimestamp(x)\n",
    "    return d.hour\n",
    "\n",
    "# train_df_prev['time'] = train_df_prev['context_timestamp'].apply(lambda x: extract_time(x))\n",
    "train_df_prev['date'] = train_df_prev['context_timestamp'].apply(lambda x: extract_date(x))\n",
    "train_df_prev['weekday'] = train_df_prev['context_timestamp'].apply(lambda x: extract_weekday(x))\n",
    "train_df_prev['hour'] = train_df_prev['context_timestamp'].apply(lambda x: extract_hour(x))\n",
    "\n",
    "m = {}\n",
    "for idx, date in enumerate(sorted(train_df_prev['date'].unique())):\n",
    "    m[date]=idx\n",
    "print(m)\n",
    "\n",
    "for idx, d in enumerate(sorted(train_df_prev['date'].unique())):\n",
    "    train_df_prev[\"day\"] = train_df_prev['date'].map(lambda x: m[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 拆解复杂类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_icl_map ... \n",
      "get_ipl_map ... \n",
      "processing predict_category_property ...\n",
      "processing item_property_list ...\n",
      "processing item_category_list ...\n",
      "generating item_category_1, item_category_2 ...\n"
     ]
    }
   ],
   "source": [
    "#简化list等复杂类型的结构\n",
    "#item_category_list全展开\n",
    "#item_property_list全展开取频率>0.05的数据\n",
    "#predict_category_property会计算跟item prop和cate的余弦相似度\n",
    "#具体是把两个list的数据拼成cate:-1和cate:prop两种方式拼成一个字符串再跟predict_category_property的数据计算相似度\n",
    "def get_icl_map(df):\n",
    "    print(\"get_icl_map ... \")\n",
    "    dfX = df.copy()\n",
    "    dfX = dfX['item_category_list'].str.split(';', expand=True)\n",
    "\n",
    "#     s = sorted(list(dfX[0].unique()) + list(dfX[1].unique()) + list(dfX[2].unique()))\n",
    "    m = {}\n",
    "    for i in dfX[0].unique():\n",
    "        if i == None:\n",
    "            continue\n",
    "        m[i] = \"1\"\n",
    "    \n",
    "    for i in dfX[1].unique():\n",
    "        if i == None:\n",
    "            continue\n",
    "        m[i] = \"2\"\n",
    "    \n",
    "    for i in dfX[2].unique():\n",
    "        if i == None:\n",
    "            continue\n",
    "        m[i] = \"3\"\n",
    "    return m\n",
    "\n",
    "def get_ipl_map(df):\n",
    "    print(\"get_ipl_map ... \")\n",
    "    df1 = df.copy()\n",
    "    dfX = df1.copy()['item_property_list'].str.split(';')\n",
    "    dfX = pd.DataFrame(dfX)\n",
    "    \n",
    "    m = collections.defaultdict(float)\n",
    "    idx = 0\n",
    "    for _, row in dfX.iterrows():\n",
    "        for i in row[0]:\n",
    "            m[i] += 1\n",
    "    \n",
    "    ll = len(dfX)\n",
    "    for k,v in m.items():\n",
    "        m[k] = v / ll\n",
    "    return m\n",
    "\n",
    "def process_complex_types(dfX, icl_map, ipl_map):\n",
    "    def filter_unless_cate(arr):\n",
    "        ret = []\n",
    "        for i in arr:\n",
    "            if i in icl_map:\n",
    "                ret.append(i)\n",
    "        if len(ret) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            return ret\n",
    "    \n",
    "    def filter_unless_prop(arr):\n",
    "        ret = []\n",
    "        for i in arr:\n",
    "            freq = ipl_map.get(i, 0.)\n",
    "            if freq > 0.05:\n",
    "                ret.append(i)\n",
    "            else:\n",
    "                ret.append(1)\n",
    "        if len(ret) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            return unique_list(ret)\n",
    "    \n",
    "    def unique_list(arr):\n",
    "        return list(set(arr))\n",
    "    \n",
    "    #{cate}:-1命中则为1分\n",
    "    #{cate}:{prop}命中则为2分\n",
    "    #后期优化权重\n",
    "    def inner_product_recall_items(line):\n",
    "        line = line.split(\"|\")\n",
    "        item_category_list = unique_list(line[0].split(\";\"))\n",
    "        item_property_list = unique_list(line[1].split(\";\"))\n",
    "        \n",
    "        whole_combines = {}\n",
    "        for cate in item_category_list:\n",
    "            tmp = cate+\":\"+\"-1\"\n",
    "            whole_combines[tmp] = 1\n",
    "            for prop in item_property_list:\n",
    "                tmp = cate+\":\"+prop\n",
    "                whole_combines[tmp] = 2\n",
    "        \n",
    "        \n",
    "                \n",
    "        predict_category_property = unique_list(line[2].split(\";\"))\n",
    "        product = 0.\n",
    "        item_vec_len = math.sqrt(len(whole_combines))\n",
    "        user_vec_len = math.sqrt(len(predict_category_property))\n",
    "        for item in predict_category_property:\n",
    "            #x1 == 1\n",
    "            #y1 == 1\n",
    "            #x1*y1 == 1\n",
    "            #x2 == 0\n",
    "            #y2 == 1\n",
    "            #x2*y2 == 0\n",
    "            #所以product由x决定 += 1/0\n",
    "            product += whole_combines.get(item, 0)\n",
    "        \n",
    "        return product/(item_vec_len*user_vec_len)\n",
    "            \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "    print(\"processing predict_category_property ...\")\n",
    "#     dfX['predict_category_property'] = dfX['predict_category_property'].str.split(';').map(lambda x: [i.split(\":\")[0] for i in x]).map(filter_unless_cate)\n",
    "    \n",
    "    dfX['predict_richness'] =  dfX['predict_category_property'].map(lambda x: 0 if len(x.strip()) == 0 else len(x.split(\";\")))\n",
    "    dfX['predict_category_property'] = dfX['item_category_list']+\"|\"+dfX['item_property_list']+\"|\"+dfX['predict_category_property']\n",
    "    dfX['predict_category_property'] = dfX['predict_category_property'].map(inner_product_recall_items)\n",
    "    \n",
    "    print(\"processing item_property_list ...\")\n",
    "    dfX['item_property_richness'] = dfX['item_property_list'].map(lambda x: 0 if len(x.strip()) == 0 else len(x.split(\";\")))\n",
    "    dfX['item_property_list'] = dfX['item_property_list'].str.split(';').map(filter_unless_prop)\n",
    "    \n",
    "    print(\"processing item_category_list ...\")\n",
    "    dfX['item_category_list'] = dfX['item_category_list'].str.split(';')\n",
    "    \n",
    "    print( \"generating item_category_1, item_category_2 ...\")\n",
    "#     dfX['item_category_list01'] = dfX['item_category_list'].map(lambda x:x[0] if x != None and len(x) > 0 else None)\n",
    "    dfX['item_category_1'] = dfX['item_category_list'].map(lambda x:x[1] if x != None and len(x) > 1 else None)\n",
    "    dfX['item_category_2'] = dfX['item_category_list'].map(lambda x:x[2] if x != None and len(x) > 2 else None)\n",
    "    \n",
    "    return dfX\n",
    "\n",
    "\n",
    "\n",
    "# aaa = process_complex_types(train_df.copy(), get_icl_map(train_df), get_ipl_map(train_df))\n",
    "\n",
    "train_df_prev = process_complex_types(train_df_prev, get_icl_map(train_df_prev), get_ipl_map(train_df_prev))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计一个用户重复看某个商品的次数+一个用户重复看某类商品的次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnt_user_item_review = train_df_prev[[\"user_id\", \"item_id\", \"instance_id\"]].groupby([\"user_id\", \"item_id\"])['instance_id'].count().to_dict() \n",
    "cnt_user_cate_review = train_df_prev[[\"user_id\", \"item_category_1\", \"instance_id\"]].groupby([\"user_id\", \"item_category_1\"])['instance_id'].count().to_dict()  \n",
    "\n",
    "class set_review_cnt:\n",
    "    def __init__(self, key1, key2, cnt_k1_k2_review):\n",
    "        self.key1 = key1\n",
    "        self.key2 = key2\n",
    "        self.tmp = collections.defaultdict(int)\n",
    "        self.cnt_k1_k2_review = cnt_k1_k2_review\n",
    "    def __call__(self, x):\n",
    "        val1,val2 = x[self.key1], x[self.key2]\n",
    "        vk = (val1, val2)\n",
    "\n",
    "        cnt = self.cnt_k1_k2_review[vk]\n",
    "        if cnt == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            \n",
    "            k = \"%s_%s\" % (val1, val2)\n",
    "            ret = self.tmp[k]\n",
    "            self.cnt_k1_k2_review[vk] -= 1\n",
    "            self.tmp[k] += 1\n",
    "            return ret\n",
    "        \n",
    "f1 = set_review_cnt(\"user_id\", \"item_id\", cnt_user_item_review)\n",
    "f2 = set_review_cnt(\"user_id\", \"item_category_1\", cnt_user_cate_review)\n",
    "train_df_prev = train_df_prev.sort_values(by=\"context_timestamp\")\n",
    "train_df_prev[\"item_review_cnt\"] = train_df_prev[[\"user_id\", \"item_id\"]].apply(f1, axis=1)\n",
    "train_df_prev[\"cate_review_cnt\"] = train_df_prev[[\"user_id\", \"item_category_1\"]].apply(f2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 转化属性增加trade_rate + trade_pv（按前一天）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 统计信息附加\n",
    "\n",
    "def calcTVTransform(df, key, key_y, filter_src, filter_dst, smoothing = 5, mean0=None):\n",
    "    if mean0 is None:\n",
    "        #计算目标的平均值做平缓用\n",
    "        mean0 = df.ix[filter_src, key_y].mean()\n",
    "        print(\"mean0:\", mean0)\n",
    "    \n",
    "    #取出key的所有值\n",
    "    df['_key1'] = df[key].astype('category').values.codes\n",
    "    \n",
    "    \n",
    "    #取出用于计算的源（后面聚合掉就没有顺序可言了）\n",
    "    df_key1_y = df.ix[filter_src, ['_key1', key_y]]\n",
    "    \n",
    "    #根据key的取值去聚合key_y的总数和总和，用户计算rate和count\n",
    "    grp1 = df_key1_y.groupby(['_key1'])\n",
    "    sum1 = grp1[key_y].aggregate(np.sum)\n",
    "    cnt1 = grp1[key_y].aggregate(np.size)\n",
    "    \n",
    "    vn_sum = 'sum_' + key\n",
    "    vn_cnt = 'cnt_' + key\n",
    "    \n",
    "    #取出dst（带序列）的所有key\n",
    "    v_codes = df.ix[filter_dst, '_key1']\n",
    "    \n",
    "    #得到_sum,_cnt，按dst的序列\n",
    "    _sum = sum1[v_codes].values\n",
    "    _cnt = cnt1[v_codes].values\n",
    "    _cnt[np.isnan(_sum)] = 0    \n",
    "    _sum[np.isnan(_sum)] = 0\n",
    "    \n",
    "    r = {}\n",
    "    r['exp'] = (_sum + smoothing * mean0)/(_cnt + smoothing)\n",
    "    r['cnt'] = _cnt\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#计算前一天的交易率set到下一天，第0天用回自己\n",
    "# tmp = train_df.copy()\n",
    "tmp = train_df_prev\n",
    "\n",
    "add_count = False\n",
    "# window = 2\n",
    "\n",
    "exp = \"exp_d_\"\n",
    "cnt = \"cnt_d_\"\n",
    "\n",
    "\n",
    "exp_numerical = {}\n",
    "cnt_numerical = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k = \"day\"\n",
    "exp_k = \"exp_d_day\"\n",
    "for day in range(0,7):\n",
    "    cal_day = day\n",
    "    set_day = day\n",
    "\n",
    "    print(\"cal %s trade_rate cnt %s set to %s\" % (k,cal_day, set_day))\n",
    "\n",
    "    #start_d - day(不含day)用于计算，结果赋值到day上\n",
    "    days1 = (tmp.day.values == cal_day)\n",
    "    days2 = (tmp.day.values == set_day)\n",
    "    ret = calcTVTransform(tmp, k, 'is_trade', days1, days2, 0)\n",
    "\n",
    "    tmp.loc[tmp.day.values == day, exp_k] = ret[\"exp\"]\n",
    "\n",
    "    exp_numerical[exp_k]=1\n",
    "\n",
    "tmp.loc[tmp.day.values == 7, exp_k] = 0.0169\n",
    "\n",
    "tmp[[exp_k, \"day\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#此处应该处理按天为梯度的数据\n",
    "for k in ['item_price_level',\n",
    "'item_sales_level',\n",
    "'item_collected_level',\n",
    "'item_pv_level',\n",
    "'user_gender_id',\n",
    "'user_age_level',\n",
    "'user_occupation_id',\n",
    "'user_star_level',\n",
    "'context_page_id',\n",
    "'shop_review_num_level',\n",
    "'shop_star_level',\n",
    "         \n",
    "\n",
    "\"item_brand_id\",\n",
    "\"item_city_id\",\n",
    "\"item_id\",\n",
    "\"shop_id\",\n",
    "          \n",
    "\"item_brand_id\",\n",
    "\"item_city_id\"\n",
    "         ]:\n",
    "    exp_k = exp+k\n",
    "    cnt_k = cnt+k\n",
    "    for day in range(0,8):\n",
    "#         start_d = max(day - window, 0)\n",
    "#         end_d = max(day - 1,0)\n",
    "        cal_day = max(day - 1, 0)\n",
    "        set_day = day\n",
    "\n",
    "        print(\"cal %s trade_rate cnt %s set to %s\" % (k,cal_day, set_day))\n",
    "        \n",
    "        #start_d - day(不含day)用于计算，结果赋值到day上\n",
    "        days1 = (tmp.day.values == cal_day)\n",
    "        days2 = (tmp.day.values == set_day)\n",
    "        ret = calcTVTransform(tmp, k, 'is_trade', days1, days2)\n",
    "            \n",
    "        tmp.loc[tmp.day.values == day, exp_k] = ret[\"exp\"]\n",
    "        \n",
    "        exp_numerical[exp_k]=1\n",
    "        if add_count:\n",
    "            cnt_numerical[cnt_k]=1\n",
    "            tmp.loc[tmp.day.values == day, cnt_k] = ret[\"cnt\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['exp_d_day', 'exp_d_item_price_level', 'exp_d_item_sales_level', 'exp_d_item_collected_level', 'exp_d_item_pv_level', 'exp_d_user_gender_id', 'exp_d_user_age_level', 'exp_d_user_occupation_id', 'exp_d_user_star_level', 'exp_d_context_page_id', 'exp_d_shop_review_num_level', 'exp_d_shop_star_level', 'exp_d_item_brand_id', 'exp_d_item_city_id', 'exp_d_item_id', 'exp_d_shop_id'])\n",
      "dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "exp_numerical = exp_numerical.keys()\n",
    "cnt_numerical = cnt_numerical.keys()\n",
    "\n",
    "print(exp_numerical)\n",
    "print(cnt_numerical)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECOVER\n"
     ]
    }
   ],
   "source": [
    "print( \"RECOVER\")\n",
    "train_df = train_df_prev.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 标记训练用的列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#标记训练数据\n",
    "\n",
    "import copy\n",
    "target=\"is_trade\"\n",
    "                          \n",
    "%run FeatureProcess.py\n",
    "                          \n",
    "                        \n",
    "categorical=[  \n",
    "                'item_price_level',\n",
    "                'item_sales_level',\n",
    "                'item_collected_level',\n",
    "                'item_pv_level',\n",
    "                'user_gender_id',\n",
    "                'user_age_level',\n",
    "                'user_occupation_id',\n",
    "                'user_star_level',\n",
    "                'context_page_id',\n",
    "                'shop_review_num_level',\n",
    "                'shop_star_level',\n",
    "                \"weekday\",\n",
    "                \"hour\",\n",
    "    \n",
    "                'item_category_1',\n",
    "                'item_category_2',\n",
    "                \n",
    "                \"item_brand_id\",\n",
    "                \"item_city_id\",\n",
    "                \"item_id\",\n",
    "                \"shop_id\",\n",
    "    \n",
    "                \"item_review_cnt\",\n",
    "                \"cate_review_cnt\"\n",
    "            ]\n",
    "\n",
    "numerical=[     'shop_review_positive_rate',\n",
    "                'shop_score_service',\n",
    "                'shop_score_delivery',\n",
    "                'shop_score_description',\n",
    "                'predict_category_property',\n",
    "                'predict_richness',\n",
    "                'item_property_richness'\n",
    "                   \n",
    "#               ]\n",
    "          ]+list(exp_numerical)\n",
    "\n",
    "listype = [\n",
    "    'item_property_list', \n",
    "#     'item_category_list'\n",
    "]\n",
    "\n",
    "                    \n",
    "            \n",
    "\n",
    "cols_tool = filter_on_cols(target, categorical, numerical, listype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_review_positive_rate</th>\n",
       "      <th>shop_score_service</th>\n",
       "      <th>shop_score_delivery</th>\n",
       "      <th>shop_score_description</th>\n",
       "      <th>predict_category_property</th>\n",
       "      <th>predict_richness</th>\n",
       "      <th>item_property_richness</th>\n",
       "      <th>exp_d_day</th>\n",
       "      <th>exp_d_item_price_level</th>\n",
       "      <th>exp_d_item_sales_level</th>\n",
       "      <th>exp_d_item_collected_level</th>\n",
       "      <th>exp_d_item_pv_level</th>\n",
       "      <th>exp_d_user_gender_id</th>\n",
       "      <th>exp_d_user_age_level</th>\n",
       "      <th>exp_d_user_occupation_id</th>\n",
       "      <th>exp_d_user_star_level</th>\n",
       "      <th>exp_d_context_page_id</th>\n",
       "      <th>exp_d_shop_review_num_level</th>\n",
       "      <th>exp_d_shop_star_level</th>\n",
       "      <th>exp_d_item_brand_id</th>\n",
       "      <th>exp_d_item_city_id</th>\n",
       "      <th>exp_d_item_id</th>\n",
       "      <th>exp_d_shop_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.994833</td>\n",
       "      <td>0.971131</td>\n",
       "      <td>0.970495</td>\n",
       "      <td>0.974870</td>\n",
       "      <td>0.104144</td>\n",
       "      <td>4.810191</td>\n",
       "      <td>34.475055</td>\n",
       "      <td>0.018794</td>\n",
       "      <td>0.019127</td>\n",
       "      <td>0.019192</td>\n",
       "      <td>0.019203</td>\n",
       "      <td>0.019182</td>\n",
       "      <td>0.019201</td>\n",
       "      <td>0.019208</td>\n",
       "      <td>0.019196</td>\n",
       "      <td>0.019191</td>\n",
       "      <td>0.019204</td>\n",
       "      <td>0.019205</td>\n",
       "      <td>0.019197</td>\n",
       "      <td>0.019156</td>\n",
       "      <td>0.019149</td>\n",
       "      <td>0.019465</td>\n",
       "      <td>0.019042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.011875</td>\n",
       "      <td>0.023607</td>\n",
       "      <td>0.023567</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>0.074287</td>\n",
       "      <td>1.795871</td>\n",
       "      <td>10.150529</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.008326</td>\n",
       "      <td>0.005930</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0.017160</td>\n",
       "      <td>0.007948</td>\n",
       "      <td>0.023115</td>\n",
       "      <td>0.020898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.010104</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.992780</td>\n",
       "      <td>0.966360</td>\n",
       "      <td>0.965677</td>\n",
       "      <td>0.969282</td>\n",
       "      <td>0.052705</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.017276</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>0.017904</td>\n",
       "      <td>0.017939</td>\n",
       "      <td>0.018869</td>\n",
       "      <td>0.017564</td>\n",
       "      <td>0.018679</td>\n",
       "      <td>0.018385</td>\n",
       "      <td>0.018735</td>\n",
       "      <td>0.017704</td>\n",
       "      <td>0.016705</td>\n",
       "      <td>0.006876</td>\n",
       "      <td>0.013794</td>\n",
       "      <td>0.004033</td>\n",
       "      <td>0.004389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972347</td>\n",
       "      <td>0.971579</td>\n",
       "      <td>0.978493</td>\n",
       "      <td>0.099015</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.019312</td>\n",
       "      <td>0.016366</td>\n",
       "      <td>0.019286</td>\n",
       "      <td>0.019162</td>\n",
       "      <td>0.019256</td>\n",
       "      <td>0.019397</td>\n",
       "      <td>0.019105</td>\n",
       "      <td>0.019032</td>\n",
       "      <td>0.019564</td>\n",
       "      <td>0.019370</td>\n",
       "      <td>0.018837</td>\n",
       "      <td>0.018953</td>\n",
       "      <td>0.017874</td>\n",
       "      <td>0.016974</td>\n",
       "      <td>0.011792</td>\n",
       "      <td>0.012949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977822</td>\n",
       "      <td>0.976966</td>\n",
       "      <td>0.983626</td>\n",
       "      <td>0.148888</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.019681</td>\n",
       "      <td>0.023363</td>\n",
       "      <td>0.022024</td>\n",
       "      <td>0.020535</td>\n",
       "      <td>0.020019</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.019854</td>\n",
       "      <td>0.020864</td>\n",
       "      <td>0.020518</td>\n",
       "      <td>0.021641</td>\n",
       "      <td>0.022550</td>\n",
       "      <td>0.024959</td>\n",
       "      <td>0.022694</td>\n",
       "      <td>0.025886</td>\n",
       "      <td>0.027273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.020021</td>\n",
       "      <td>0.109656</td>\n",
       "      <td>0.037044</td>\n",
       "      <td>0.035202</td>\n",
       "      <td>0.182390</td>\n",
       "      <td>0.023104</td>\n",
       "      <td>0.027449</td>\n",
       "      <td>0.022760</td>\n",
       "      <td>0.054228</td>\n",
       "      <td>0.026027</td>\n",
       "      <td>0.084623</td>\n",
       "      <td>0.122234</td>\n",
       "      <td>0.231820</td>\n",
       "      <td>0.189505</td>\n",
       "      <td>0.299543</td>\n",
       "      <td>0.262301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       shop_review_positive_rate  shop_score_service  shop_score_delivery  \\\n",
       "count              496509.000000       496509.000000        496509.000000   \n",
       "mean                    0.994833            0.971131             0.970495   \n",
       "std                     0.011875            0.023607             0.023567   \n",
       "min                    -1.000000           -1.000000            -1.000000   \n",
       "25%                     0.992780            0.966360             0.965677   \n",
       "50%                     1.000000            0.972347             0.971579   \n",
       "75%                     1.000000            0.977822             0.976966   \n",
       "max                     1.000000            1.000000             1.000000   \n",
       "\n",
       "       shop_score_description  predict_category_property  predict_richness  \\\n",
       "count           496509.000000              496509.000000     496509.000000   \n",
       "mean                 0.974870                   0.104144          4.810191   \n",
       "std                  0.024823                   0.074287          1.795871   \n",
       "min                 -1.000000                   0.000000          1.000000   \n",
       "25%                  0.969282                   0.052705          3.000000   \n",
       "50%                  0.978493                   0.099015          5.000000   \n",
       "75%                  0.983626                   0.148888          6.000000   \n",
       "max                  1.000000                   0.632456         14.000000   \n",
       "\n",
       "       item_property_richness      exp_d_day  exp_d_item_price_level  \\\n",
       "count           496509.000000  496509.000000           496509.000000   \n",
       "mean                34.475055       0.018794                0.019127   \n",
       "std                 10.150529       0.001128                0.008326   \n",
       "min                  6.000000       0.016900                0.000991   \n",
       "25%                 29.000000       0.017276                0.014194   \n",
       "50%                 33.000000       0.019312                0.016366   \n",
       "75%                 39.000000       0.019681                0.023363   \n",
       "max                100.000000       0.020021                0.109656   \n",
       "\n",
       "       exp_d_item_sales_level  exp_d_item_collected_level  \\\n",
       "count           496509.000000               496509.000000   \n",
       "mean                 0.019192                    0.019203   \n",
       "std                  0.005930                    0.003000   \n",
       "min                  0.000521                    0.000545   \n",
       "25%                  0.015125                    0.017904   \n",
       "50%                  0.019286                    0.019162   \n",
       "75%                  0.022024                    0.020535   \n",
       "max                  0.037044                    0.035202   \n",
       "\n",
       "       exp_d_item_pv_level  exp_d_user_gender_id  exp_d_user_age_level  \\\n",
       "count        496509.000000         496509.000000         496509.000000   \n",
       "mean              0.019182              0.019201              0.019208   \n",
       "std               0.002667              0.001897              0.003049   \n",
       "min               0.000722              0.010104              0.000985   \n",
       "25%               0.017939              0.018869              0.017564   \n",
       "50%               0.019256              0.019397              0.019105   \n",
       "75%               0.020019              0.019800              0.020800   \n",
       "max               0.182390              0.023104              0.027449   \n",
       "\n",
       "       exp_d_user_occupation_id  exp_d_user_star_level  exp_d_context_page_id  \\\n",
       "count             496509.000000          496509.000000          496509.000000   \n",
       "mean                   0.019196               0.019191               0.019204   \n",
       "std                    0.001746               0.002817               0.002717   \n",
       "min                    0.000985               0.000985               0.004171   \n",
       "25%                    0.018679               0.018385               0.018735   \n",
       "50%                    0.019032               0.019564               0.019370   \n",
       "75%                    0.019854               0.020864               0.020518   \n",
       "max                    0.022760               0.054228               0.026027   \n",
       "\n",
       "       exp_d_shop_review_num_level  exp_d_shop_star_level  \\\n",
       "count                496509.000000          496509.000000   \n",
       "mean                      0.019205               0.019197   \n",
       "std                       0.003738               0.003774   \n",
       "min                       0.000925               0.000531   \n",
       "25%                       0.017704               0.016705   \n",
       "50%                       0.018837               0.018953   \n",
       "75%                       0.021641               0.022550   \n",
       "max                       0.084623               0.122234   \n",
       "\n",
       "       exp_d_item_brand_id  exp_d_item_city_id  exp_d_item_id  exp_d_shop_id  \n",
       "count        496509.000000       496509.000000  496509.000000  496509.000000  \n",
       "mean              0.019156            0.019149       0.019465       0.019042  \n",
       "std               0.017160            0.007948       0.023115       0.020898  \n",
       "min               0.000229            0.000455       0.000287       0.000237  \n",
       "25%               0.006876            0.013794       0.004033       0.004389  \n",
       "50%               0.017874            0.016974       0.011792       0.012949  \n",
       "75%               0.024959            0.022694       0.025886       0.027273  \n",
       "max               0.231820            0.189505       0.299543       0.262301  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[cols_tool.get_raw_numerical_cols()].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 平滑处理连续型数据最后对复杂类型做onehot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_review_positive_rate</th>\n",
       "      <th>shop_score_service</th>\n",
       "      <th>shop_score_delivery</th>\n",
       "      <th>shop_score_description</th>\n",
       "      <th>predict_category_property</th>\n",
       "      <th>predict_richness</th>\n",
       "      <th>item_property_richness</th>\n",
       "      <th>exp_d_day</th>\n",
       "      <th>exp_d_item_price_level</th>\n",
       "      <th>exp_d_item_sales_level</th>\n",
       "      <th>exp_d_item_collected_level</th>\n",
       "      <th>exp_d_item_pv_level</th>\n",
       "      <th>exp_d_user_gender_id</th>\n",
       "      <th>exp_d_user_age_level</th>\n",
       "      <th>exp_d_user_occupation_id</th>\n",
       "      <th>exp_d_user_star_level</th>\n",
       "      <th>exp_d_context_page_id</th>\n",
       "      <th>exp_d_shop_review_num_level</th>\n",
       "      <th>exp_d_shop_star_level</th>\n",
       "      <th>exp_d_item_brand_id</th>\n",
       "      <th>exp_d_item_city_id</th>\n",
       "      <th>exp_d_item_id</th>\n",
       "      <th>exp_d_shop_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "      <td>496509.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.982014</td>\n",
       "      <td>0.865794</td>\n",
       "      <td>0.827843</td>\n",
       "      <td>0.883320</td>\n",
       "      <td>0.164666</td>\n",
       "      <td>0.293092</td>\n",
       "      <td>0.302926</td>\n",
       "      <td>0.606917</td>\n",
       "      <td>0.166898</td>\n",
       "      <td>0.511220</td>\n",
       "      <td>0.538369</td>\n",
       "      <td>0.101611</td>\n",
       "      <td>0.699759</td>\n",
       "      <td>0.688612</td>\n",
       "      <td>0.836325</td>\n",
       "      <td>0.341940</td>\n",
       "      <td>0.687828</td>\n",
       "      <td>0.218402</td>\n",
       "      <td>0.153373</td>\n",
       "      <td>0.081723</td>\n",
       "      <td>0.098886</td>\n",
       "      <td>0.064086</td>\n",
       "      <td>0.071759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.032251</td>\n",
       "      <td>0.043904</td>\n",
       "      <td>0.054594</td>\n",
       "      <td>0.056408</td>\n",
       "      <td>0.117458</td>\n",
       "      <td>0.138144</td>\n",
       "      <td>0.107984</td>\n",
       "      <td>0.361303</td>\n",
       "      <td>0.076621</td>\n",
       "      <td>0.162354</td>\n",
       "      <td>0.086564</td>\n",
       "      <td>0.014680</td>\n",
       "      <td>0.145956</td>\n",
       "      <td>0.115209</td>\n",
       "      <td>0.080191</td>\n",
       "      <td>0.052908</td>\n",
       "      <td>0.124316</td>\n",
       "      <td>0.044658</td>\n",
       "      <td>0.031012</td>\n",
       "      <td>0.074096</td>\n",
       "      <td>0.042041</td>\n",
       "      <td>0.077242</td>\n",
       "      <td>0.079743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.974731</td>\n",
       "      <td>0.842328</td>\n",
       "      <td>0.798142</td>\n",
       "      <td>0.856064</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.244681</td>\n",
       "      <td>0.120499</td>\n",
       "      <td>0.121504</td>\n",
       "      <td>0.399855</td>\n",
       "      <td>0.500887</td>\n",
       "      <td>0.094769</td>\n",
       "      <td>0.674225</td>\n",
       "      <td>0.626489</td>\n",
       "      <td>0.812573</td>\n",
       "      <td>0.326793</td>\n",
       "      <td>0.666383</td>\n",
       "      <td>0.200471</td>\n",
       "      <td>0.132899</td>\n",
       "      <td>0.028698</td>\n",
       "      <td>0.070562</td>\n",
       "      <td>0.012521</td>\n",
       "      <td>0.015845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870375</td>\n",
       "      <td>0.832816</td>\n",
       "      <td>0.899184</td>\n",
       "      <td>0.156556</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.287234</td>\n",
       "      <td>0.772863</td>\n",
       "      <td>0.141488</td>\n",
       "      <td>0.513787</td>\n",
       "      <td>0.537175</td>\n",
       "      <td>0.102018</td>\n",
       "      <td>0.714830</td>\n",
       "      <td>0.684715</td>\n",
       "      <td>0.828809</td>\n",
       "      <td>0.348955</td>\n",
       "      <td>0.695428</td>\n",
       "      <td>0.214012</td>\n",
       "      <td>0.151369</td>\n",
       "      <td>0.076188</td>\n",
       "      <td>0.087382</td>\n",
       "      <td>0.038448</td>\n",
       "      <td>0.048508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896039</td>\n",
       "      <td>0.864508</td>\n",
       "      <td>0.923249</td>\n",
       "      <td>0.235412</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.351064</td>\n",
       "      <td>0.891105</td>\n",
       "      <td>0.205879</td>\n",
       "      <td>0.588760</td>\n",
       "      <td>0.576776</td>\n",
       "      <td>0.106222</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.748742</td>\n",
       "      <td>0.866525</td>\n",
       "      <td>0.373371</td>\n",
       "      <td>0.747943</td>\n",
       "      <td>0.247507</td>\n",
       "      <td>0.180926</td>\n",
       "      <td>0.106783</td>\n",
       "      <td>0.117639</td>\n",
       "      <td>0.085545</td>\n",
       "      <td>0.103168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       shop_review_positive_rate  shop_score_service  shop_score_delivery  \\\n",
       "count              496509.000000       496509.000000        496509.000000   \n",
       "mean                    0.982014            0.865794             0.827843   \n",
       "std                     0.032251            0.043904             0.054594   \n",
       "min                     0.000000            0.000000             0.000000   \n",
       "25%                     0.974731            0.842328             0.798142   \n",
       "50%                     1.000000            0.870375             0.832816   \n",
       "75%                     1.000000            0.896039             0.864508   \n",
       "max                     1.000000            1.000000             1.000000   \n",
       "\n",
       "       shop_score_description  predict_category_property  predict_richness  \\\n",
       "count           496509.000000              496509.000000     496509.000000   \n",
       "mean                 0.883320                   0.164666          0.293092   \n",
       "std                  0.056408                   0.117458          0.138144   \n",
       "min                  0.000000                   0.000000          0.000000   \n",
       "25%                  0.856064                   0.083333          0.153846   \n",
       "50%                  0.899184                   0.156556          0.307692   \n",
       "75%                  0.923249                   0.235412          0.384615   \n",
       "max                  1.000000                   1.000000          1.000000   \n",
       "\n",
       "       item_property_richness      exp_d_day  exp_d_item_price_level  \\\n",
       "count           496509.000000  496509.000000           496509.000000   \n",
       "mean                 0.302926       0.606917                0.166898   \n",
       "std                  0.107984       0.361303                0.076621   \n",
       "min                  0.000000       0.000000                0.000000   \n",
       "25%                  0.244681       0.120499                0.121504   \n",
       "50%                  0.287234       0.772863                0.141488   \n",
       "75%                  0.351064       0.891105                0.205879   \n",
       "max                  1.000000       1.000000                1.000000   \n",
       "\n",
       "       exp_d_item_sales_level  exp_d_item_collected_level  \\\n",
       "count           496509.000000               496509.000000   \n",
       "mean                 0.511220                    0.538369   \n",
       "std                  0.162354                    0.086564   \n",
       "min                  0.000000                    0.000000   \n",
       "25%                  0.399855                    0.500887   \n",
       "50%                  0.513787                    0.537175   \n",
       "75%                  0.588760                    0.576776   \n",
       "max                  1.000000                    1.000000   \n",
       "\n",
       "       exp_d_item_pv_level  exp_d_user_gender_id  exp_d_user_age_level  \\\n",
       "count        496509.000000         496509.000000         496509.000000   \n",
       "mean              0.101611              0.699759              0.688612   \n",
       "std               0.014680              0.145956              0.115209   \n",
       "min               0.000000              0.000000              0.000000   \n",
       "25%               0.094769              0.674225              0.626489   \n",
       "50%               0.102018              0.714830              0.684715   \n",
       "75%               0.106222              0.745833              0.748742   \n",
       "max               1.000000              1.000000              1.000000   \n",
       "\n",
       "       exp_d_user_occupation_id  exp_d_user_star_level  exp_d_context_page_id  \\\n",
       "count             496509.000000          496509.000000          496509.000000   \n",
       "mean                   0.836325               0.341940               0.687828   \n",
       "std                    0.080191               0.052908               0.124316   \n",
       "min                    0.000000               0.000000               0.000000   \n",
       "25%                    0.812573               0.326793               0.666383   \n",
       "50%                    0.828809               0.348955               0.695428   \n",
       "75%                    0.866525               0.373371               0.747943   \n",
       "max                    1.000000               1.000000               1.000000   \n",
       "\n",
       "       exp_d_shop_review_num_level  exp_d_shop_star_level  \\\n",
       "count                496509.000000          496509.000000   \n",
       "mean                      0.218402               0.153373   \n",
       "std                       0.044658               0.031012   \n",
       "min                       0.000000               0.000000   \n",
       "25%                       0.200471               0.132899   \n",
       "50%                       0.214012               0.151369   \n",
       "75%                       0.247507               0.180926   \n",
       "max                       1.000000               1.000000   \n",
       "\n",
       "       exp_d_item_brand_id  exp_d_item_city_id  exp_d_item_id  exp_d_shop_id  \n",
       "count        496509.000000       496509.000000  496509.000000  496509.000000  \n",
       "mean              0.081723            0.098886       0.064086       0.071759  \n",
       "std               0.074096            0.042041       0.077242       0.079743  \n",
       "min               0.000000            0.000000       0.000000       0.000000  \n",
       "25%               0.028698            0.070562       0.012521       0.015845  \n",
       "50%               0.076188            0.087382       0.038448       0.048508  \n",
       "75%               0.106783            0.117639       0.085545       0.103168  \n",
       "max               1.000000            1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#数据的预处理\n",
    "#double系列(例如好评率)的数据存在一个问题，没有考虑到评论量，所以乘了一个评论level，类似 好评率*评论数(分桶了) = 好评量(分桶了)\n",
    "#fillempty把-1设置成-0.01，配合mov2pos使用\n",
    "#mov2pos把有<0的数据都集体-min，如果一个数据是0-1，有-1出现的时候，上面设置成了-0.01，所以这列数据真实是-0.01 - 1,然后我会集体-(-0.01)\n",
    "#norm用了最大值最小值norm\n",
    "%run FeatureProcess.py\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def bucketizer(df, key, bins):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    prefix=\"*BUK*_\"\n",
    "    df[prefix+key] = pd.cut(df[key].values, bins=bins, retbins=False)\n",
    "    df[prefix+key] = le.fit_transform(df[prefix+key].copy())\n",
    "    return df\n",
    "\n",
    "\n",
    "def layering(df, key, by_key):\n",
    "    uniqv = df[by_key].unique()\n",
    "    keys = []\n",
    "    for v in uniqv:\n",
    "        indexer = (df[by_key] == v)\n",
    "        new_key = \"*%sLAY*_%s\" % (str(v), key)\n",
    "        df.loc[indexer, new_key] = df[indexer][key]\n",
    "        keys.append(new_key)\n",
    "    return df, keys\n",
    "\n",
    "# #分桶+打散\n",
    "# print(\"bucketizer ... \")\n",
    "# train_df = bucketizer(train_df, \"shop_review_num_level\", 5)\n",
    "\n",
    "# print(\"layering ... \")\n",
    "# new_n = []\n",
    "# for n in numerical:\n",
    "#     train_df, keys = layering(train_df, n, '*BUK*_shop_review_num_level')\n",
    "#     new_n += keys\n",
    "\n",
    "\n",
    "\n",
    "featProc = FeatureProcess(target=target, categorical=categorical, numerical=numerical, listype = listype)\n",
    "# for n in numerical:\n",
    "#     featProc.addLayeringOrgKeys(n)\n",
    "# train_df[\"shop_review_num_level\"] = train_df[\"shop_review_num_level\"]\n",
    "# train_df[\"shop_review_positive_rate\"] = train_df[\"shop_review_positive_rate\"]*train_df[\"shop_review_num_level\"]\n",
    "# train_df[\"shop_score_service\"] = train_df[\"shop_score_service\"]*train_df[\"shop_review_num_level\"]\n",
    "# train_df[\"shop_score_delivery\"] = train_df[\"shop_score_delivery\"]*train_df[\"shop_review_num_level\"]\n",
    "# train_df[\"shop_score_description\"] = train_df[\"shop_score_description\"]*train_df[\"shop_review_num_level\"]\n",
    "\n",
    "train_df = featProc.fillempty(train_df, -0.01)\n",
    "# train_df = featProc.mov2pos(train_df)\n",
    "train_df = featProc.mov2mean(train_df)\n",
    "train_df = featProc.norm(train_df)\n",
    "train_df[cols_tool.get_raw_numerical_cols()].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #onehot没啥好说的，就是onehot，toOneHotList实现有点不同分开了而已\n",
    "\n",
    "\n",
    "# # train_df = featProc.toOneHot(train_df)\n",
    "# train_df = featProc.toOneHotList(train_df)\n",
    "\n",
    "# # train_df = featProc.cacheRun(featProc.toOneHot, train_df)\n",
    "\n",
    "# for c in train_df.columns:\n",
    "#     print(c)\n",
    "\n",
    "# print train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ffmyh.py\n",
    "\n",
    "    \n",
    "# def train_and_test_combine(train_df, test_df, res_df):\n",
    "    \n",
    "#     X_train = train_df.copy()\n",
    "#     del X_train['is_trade']\n",
    "#     y_train = train_df['is_trade']\n",
    "    \n",
    "#     X_test = test_df.copy()\n",
    "#     del X_test['is_trade']\n",
    "#     y_test = test_df['is_trade']\n",
    "    \n",
    "    \n",
    "    \n",
    "#     model = xgboost.XGBClassifier(nthread=7,max_depth=5)\n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     y_prev_predict_train = pd.DataFrame(model.predict_proba(X_train))\n",
    "#     y_prev_predict_train[\"idx\"] = X_train.index\n",
    "#     y_prev_predict_train = y_prev_predict_train.set_index(\"idx\")\n",
    "#     X_train[\"y_prev_predict\"] = y_prev_predict_train[1]\n",
    "    \n",
    "#     y_prev_predict_test = pd.DataFrame(model.predict_proba(X_test))\n",
    "#     y_prev_predict_test[\"idx\"] = X_test.index\n",
    "#     y_prev_predict_test = y_prev_predict_test.set_index(\"idx\")\n",
    "#     X_test[\"y_prev_predict\"] = y_prev_predict_test[1]\n",
    "    \n",
    "    \n",
    "# #     X_train = X_train.fillna(0)\n",
    "# #     X_test = X_test.fillna(0)\n",
    "    \n",
    "    \n",
    "#     model = LogisticRegression(max_iter=1000)\n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "#     train_lls = log_loss(y_train,model.predict_proba(X_train))\n",
    "#     test_lls = log_loss(y_test,model.predict_proba(X_test))\n",
    "#     del train_df\n",
    "#     del test_df\n",
    "    \n",
    "#     del X_train\n",
    "#     del y_train\n",
    "#     del X_test\n",
    "#     del y_test\n",
    "    \n",
    "#     return train_lls, test_lls\n",
    "    \n",
    "\n",
    "def train_and_test_xgboost(train_df, test_df, res_df):    \n",
    "    X_train = train_df.copy()\n",
    "    del X_train['is_trade']\n",
    "    y_train = train_df['is_trade']\n",
    "    \n",
    "    X_test = test_df.copy()\n",
    "    del X_test['is_trade']\n",
    "    y_test = test_df['is_trade']\n",
    "    \n",
    "    \n",
    "#     model = xgboost.XGBClassifier(reg_lambda=1.5,learning_rate=0.1,reg_alpha=0,nthread=7,n_estimators=100,max_depth=10)\n",
    "    # model = xgboost.XGBClassifier(subsample=0.9,colsample_bytree=0.9,n_estimators=500,max_depth=7,nthread=3)\n",
    "    model = xgboost.XGBClassifier(n_jobs=7, max_depth=3, n_estimators=230)\n",
    "\n",
    "#     model = xgboost.XGBClassifier(subsample=0.9,colsample_bytree=0.9,n_estimators=50,max_depth=3,nthread=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    fig, ax = plt.subplots(figsize=(12,18))\n",
    "    xgboost.plot_importance(model,ax=ax)\n",
    "    plt.show()\n",
    "    \n",
    "    train_lls = log_loss(y_train,model.predict_proba(X_train))\n",
    "    test_lls = log_loss(y_test,model.predict_proba(X_test))\n",
    "    \n",
    "    if type(res_df) != type(None):\n",
    "        # del res_df[\"is_trade\"]\n",
    "        res_df = res_df.reset_index(drop=True)\n",
    "        instance_id_list = res_df[[\"instance_id\"]]\n",
    "        del res_df[\"instance_id\"]\n",
    "        predicted_score = pd.DataFrame(model.predict_proba(res_df))\n",
    "        \n",
    "        instance_id_list[\"predicted_score\"] = predicted_score[1]\n",
    "        instance_id_list.to_csv(\"xgb_8160.csv\",index=False,sep=' ')\n",
    "        \n",
    "    \n",
    "    del train_df\n",
    "    del test_df\n",
    "    \n",
    "    del X_train\n",
    "    del y_train\n",
    "    del X_test\n",
    "    del y_test\n",
    "    \n",
    "    return train_lls, test_lls\n",
    "\n",
    "def train_and_test_lr(train_df, test_df, res_df):    \n",
    "    X_train = train_df.copy().fillna(0)\n",
    "    del X_train['is_trade']\n",
    "    y_train = train_df['is_trade']\n",
    "    \n",
    "    X_test = test_df.copy().fillna(0)\n",
    "    del X_test['is_trade']\n",
    "    y_test = test_df['is_trade']\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = LogisticRegression(C=1.0, n_jobs=7,tol=1e-6, max_iter=2000)\n",
    "    model.fit(X_train.values, y_train)\n",
    "#     for idx, val in enumerate(list(X_train.columns)):\n",
    "#         print(\"%s=%s\" %(val,list(model.coef_[0])[idx]))\n",
    "\n",
    "\n",
    "    train_lls = log_loss(y_train,model.predict_proba(X_train))\n",
    "    test_lls = log_loss(y_test,model.predict_proba(X_test))\n",
    "    \n",
    "    if type(res_df) != type(None):\n",
    "        res_df = res_df.copy().fillna(0)\n",
    "        # del res_df[\"is_trade\"]\n",
    "        res_df = res_df.reset_index(drop=True)\n",
    "        instance_id_list = res_df[[\"instance_id\"]]\n",
    "        del res_df[\"instance_id\"]\n",
    "        predicted_score = pd.DataFrame(model.predict_proba(res_df))\n",
    "        \n",
    "        instance_id_list[\"predicted_score\"] = predicted_score[1]\n",
    "        instance_id_list.to_csv(\"lr_res.csv\",index=False,sep=' ')\n",
    "    \n",
    "    del train_df\n",
    "    del test_df\n",
    "    \n",
    "    del X_train\n",
    "    del y_train\n",
    "    del X_test\n",
    "    del y_test\n",
    "    \n",
    "    return train_lls, test_lls\n",
    "\n",
    "def train_and_test_randomforest(train_df, test_df, res_df):    \n",
    "    X_train = train_df.copy()\n",
    "    del X_train['is_trade']\n",
    "    y_train = train_df['is_trade']\n",
    "    \n",
    "    X_test = test_df.copy()\n",
    "    del X_test['is_trade']\n",
    "    y_test = test_df['is_trade']\n",
    "    \n",
    "#     rf = RandomForestClassifier(n_estimators=32, max_depth=40, min_samples_split=100, min_samples_leaf=10,  criterion='entropy',\n",
    "#                         max_features=8, verbose = 1,  bootstrap=False, n_jobs=10)\n",
    "#     RandomForestClassifier(criterion='entropy',n_estimators=100,n_jobs=15)\n",
    "\n",
    "    model = RandomForestClassifier(n_jobs=7, n_estimators=100, max_depth=10, min_samples_split=100, min_samples_leaf=10,  criterion='entropy', max_features=8, verbose = 1,  bootstrap=False)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    ft_w = pd.DataFrame(model.feature_importances_, columns=[\"weights\"], index = list(X_train.columns))\n",
    "    print( ft_w.sort_values(\"weights\", ascending=False))\n",
    "#     fig, ax = plt.subplots(figsize=(12,18))\n",
    "#     xgboost.plot_importance(model,ax=ax)\n",
    "#     plt.show()\n",
    "    \n",
    "    train_lls = log_loss(y_train,model.predict_proba(X_train))\n",
    "    test_lls = log_loss(y_test,model.predict_proba(X_test))\n",
    "    \n",
    "    if type(res_df) != type(None):\n",
    "        # del res_df[\"is_trade\"]\n",
    "        res_df = res_df.reset_index(drop=True)\n",
    "        instance_id_list = res_df[[\"instance_id\"]]\n",
    "        del res_df[\"instance_id\"]\n",
    "        predicted_score = pd.DataFrame(model.predict_proba(res_df))\n",
    "        \n",
    "        instance_id_list[\"predicted_score\"] = predicted_score[1]\n",
    "        instance_id_list.to_csv(\"rf_8211.csv\",index=False,sep=' ')\n",
    "        \n",
    "    del train_df\n",
    "    del test_df\n",
    "    \n",
    "    del X_train\n",
    "    del y_train\n",
    "    del X_test\n",
    "    del y_test\n",
    "    \n",
    "    return train_lls, test_lls\n",
    "\n",
    "def train_and_test_gbdt(train_df, test_df, res_df):\n",
    "    X_train = train_df.copy()\n",
    "    del X_train['is_trade']\n",
    "    y_train = train_df['is_trade']\n",
    "    \n",
    "    X_test = test_df.copy()\n",
    "    del X_test['is_trade']\n",
    "    y_test = test_df['is_trade']\n",
    "    \n",
    "    model = GradientBoostingClassifier(n_estimators=100, max_depth=10, min_samples_split=100, min_samples_leaf=10, max_features=4)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    train_lls = log_loss(y_train,model.predict_proba(X_train))\n",
    "    test_lls = log_loss(y_test,model.predict_proba(X_test))\n",
    "    \n",
    "    if type(res_df) != type(None):\n",
    "        del res_df[\"is_trade\"]\n",
    "        res_df = res_df.reset_index(drop=True)\n",
    "        instance_id_list = res_df[[\"instance_id\"]]\n",
    "        del res_df[\"instance_id\"]\n",
    "        predicted_score = pd.DataFrame(model.predict_proba(res_df))\n",
    "        \n",
    "        instance_id_list[\"predicted_score\"] = predicted_score[1]\n",
    "        instance_id_list.to_csv(\"gbdt_res.csv\",index=False,sep=' ')\n",
    "        \n",
    "    del train_df\n",
    "    del test_df\n",
    "    \n",
    "    del X_train\n",
    "    del y_train\n",
    "    del X_test\n",
    "    del y_test\n",
    "    \n",
    "    return train_lls, test_lls\n",
    "\n",
    "\n",
    "def train_and_test_lgb(train_df, test_df, res_df, target, features, categorical):\n",
    "    X_train = train_df.copy()\n",
    "    del X_train['is_trade']\n",
    "    y_train = train_df['is_trade']\n",
    "    \n",
    "    X_test = test_df.copy()\n",
    "    del X_test['is_trade']\n",
    "    y_test = test_df['is_trade']\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     test['lgb_predict'] = clf.predict_proba(test[features],)[:, 1]\n",
    "#     print(log_loss(test[target], test['lgb_predict']))\n",
    "\n",
    "    \n",
    "    model = lgb.LGBMClassifier(num_leaves=10, max_depth=7, n_estimators=80, n_jobs=4)\n",
    "    model.fit(X_train, y_train, feature_name=features,categorical_feature=categorical)\n",
    "    \n",
    "    ft_w = pd.DataFrame(model.feature_importances_, columns=[\"weights\"], index = list(X_train.columns))\n",
    "    print(ft_w)\n",
    "#     fig, ax = plt.subplots(figsize=(12,18))\n",
    "#     xgboost.plot_importance(model,ax=ax)\n",
    "#     plt.show()\n",
    "    \n",
    "    train_lls = log_loss(y_train,model.predict_proba(X_train))\n",
    "    test_lls = log_loss(y_test,model.predict_proba(X_test))\n",
    "    \n",
    "    if type(res_df) != type(None):\n",
    "        del res_df[\"is_trade\"]\n",
    "        res_df = res_df.reset_index(drop=True)\n",
    "        instance_id_list = res_df[[\"instance_id\"]]\n",
    "        del res_df[\"instance_id\"]\n",
    "        predicted_score = pd.DataFrame(model.predict_proba(res_df))\n",
    "        \n",
    "        instance_id_list[\"predicted_score\"] = predicted_score[1]\n",
    "        instance_id_list.to_csv(\"lgb_res.csv\",index=False,sep=' ')\n",
    "        \n",
    "    del train_df\n",
    "    del test_df\n",
    "    \n",
    "    del X_train\n",
    "    del y_train\n",
    "    del X_test\n",
    "    del y_test\n",
    "    \n",
    "    return train_lls, test_lls\n",
    "\n",
    "\n",
    "def train_and_test_FFM(train_df, test_df, res_df):\n",
    "    global cols_tool\n",
    "    \n",
    "    model = FFM(target=cols_tool.target, categorical=cols_tool.categorical, numerical=cols_tool.numerical, listype=cols_tool.listype,\n",
    "                                        reg_param = 0.0004,\n",
    "                                        k = 4,\n",
    "                                        iter_max = 500,\n",
    "                                        learing_rate = 0.1,\n",
    "                                        threads = 7,\n",
    "                                        auto_stop = False,\n",
    "                                        quiet = False,\n",
    "                                        no_norm = False)\n",
    "\n",
    "\n",
    "    \n",
    "    model.fit(train_df, test_df)\n",
    "    \n",
    "    train_lls = log_loss(train_df[\"is_trade\"],model.predict_proba(train_df))\n",
    "    test_lls = log_loss(test_df[\"is_trade\"],model.predict_proba(test_df))\n",
    "    \n",
    "    \n",
    "    if type(res_df) != type(None):\n",
    "        del res_df[\"is_trade\"]\n",
    "        res_df = res_df.reset_index(drop=True)\n",
    "        instance_id_list = res_df[[\"instance_id\"]]\n",
    "        del res_df[\"instance_id\"]\n",
    "        predicted_score = pd.DataFrame(model.predict_proba(res_df))\n",
    "        \n",
    "        instance_id_list[\"predicted_score\"] = predicted_score[1]\n",
    "        instance_id_list.to_csv(\"ffm.csv\",index=False,sep=' ')\n",
    "        \n",
    "    \n",
    "    return train_lls, test_lls\n",
    "\n",
    "\n",
    "def select_best_features(df, precent=0.8):\n",
    "    from sklearn.feature_selection import SelectKBest,chi2 \n",
    "    df = df.copy().replace(-1, 0).fillna(0)\n",
    "    \n",
    "    for u in df.columns:\n",
    "        df[df[u] == -1] = 0\n",
    "\n",
    "    X_train = df.copy()\n",
    "    del X_train['is_trade']\n",
    "    y_train = df['is_trade']\n",
    "    \n",
    "    c = int(len(X_train.columns) * precent)\n",
    "    skb = SelectKBest(chi2,k=c)\n",
    "    skb.fit_transform(X_train,y_train)\n",
    "    \n",
    "    old_fea = list(X_train.columns)\n",
    "    new_fea = []\n",
    "    for idx, b in enumerate(list(skb.get_support())):\n",
    "        if b:\n",
    "            new_fea.append(old_fea[idx])\n",
    "        else:\n",
    "            print(\"Filter feature:%s\" % old_fea[idx])\n",
    "    return new_fea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开搞！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org dataset = 496509\n",
      "0    78268\n",
      "3    71199\n",
      "1    70931\n",
      "2    68387\n",
      "4    68318\n",
      "5    63614\n",
      "6    57421\n",
      "7    18371\n",
      "Name: day, dtype: int64\n",
      "0    78268\n",
      "3    71199\n",
      "1    70931\n",
      "2    68387\n",
      "4    68318\n",
      "5    63614\n",
      "6    57421\n",
      "7    18371\n",
      "Name: day, dtype: int64\n",
      "res dataset = 18371\n",
      "valid dateset = 57421\n",
      "train dateset = 478138\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAAQPCAYAAAAqHcuBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wcdQFQV24kZagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a8f2efe48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prehawkmac/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost 21 dimension TrainLogLoss = 0.0873422651439 | TestLogLoss = 0.0800819499604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:   47.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            weights\n",
      "item_price_level           0.166678\n",
      "item_review_cnt            0.102134\n",
      "shop_score_delivery        0.095935\n",
      "shop_score_service         0.086855\n",
      "item_sales_level           0.079476\n",
      "item_category_1            0.065676\n",
      "shop_score_description     0.064832\n",
      "hour                       0.061632\n",
      "shop_review_positive_rate  0.039599\n",
      "user_age_level             0.035369\n",
      "user_star_level            0.034416\n",
      "shop_review_num_level      0.023818\n",
      "item_collected_level       0.022644\n",
      "shop_star_level            0.021794\n",
      "cate_review_cnt            0.021521\n",
      "context_page_id            0.021343\n",
      "item_pv_level              0.017670\n",
      "weekday                    0.013315\n",
      "user_occupation_id         0.009380\n",
      "item_category_2            0.008169\n",
      "user_gender_id             0.007743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest 21 dimension TrainLogLoss = 0.084547560987 | TestLogLoss = 0.0771327729286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prehawkmac/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#这块一般不怎么需要改了，拿最后一天做验证\n",
    "#注意下面验证版和测试版，测试版是我们自己玩的，验证版是扔线上的，通过注释不同的跑就行了\n",
    "\n",
    "\n",
    "# %run BaseFrame.py\n",
    "% run ../util/time_series_split.py\n",
    "\n",
    "tmp_train_df = train_df.copy().fillna(-1)\n",
    "tmp_train_df[\"item_category_1\"] = tmp_train_df[\"item_category_1\"].astype('int')\n",
    "tmp_train_df[\"item_category_2\"] = tmp_train_df[\"item_category_2\"].astype('int')\n",
    "\n",
    "# tmp_train_df[\"user_gender_id*shop_review_positive_rate\"] = tmp_train_df[\"user_gender_id\"] * (1+tmp_train_df[\"shop_review_positive_rate\"])\n",
    "\n",
    "# tmp_train_df[\"user_gender_id*shop_star_level\"] = tmp_train_df[\"user_gender_id\"] * (1+tmp_train_df[\"shop_star_level\"])\n",
    "\n",
    "\n",
    "cols_tool.fit(train_df)\n",
    "\n",
    "categorical_one_hot_cols = cols_tool.get_onehoted_cols(\"categorical\")\n",
    "listype_one_hot_cols = cols_tool.get_onehoted_cols(\"listype\")\n",
    "\n",
    "index_col = \"instance_id\"\n",
    "\n",
    "\n",
    "categorical_cols = cols_tool.get_raw_categorical_cols()\n",
    "listype_cols = cols_tool.get_raw_listype_cols()\n",
    "numerical_cols = cols_tool.get_raw_numerical_cols()\n",
    "target_col = cols_tool.get_raw_target_col()\n",
    "\n",
    "\n",
    "print(\"org dataset = %s\" % len(tmp_train_df))\n",
    "print(tmp_train_df[\"day\"].value_counts())\n",
    "\n",
    "\n",
    "# tmp_train_df = featProc.balance_pos_neg_sample(tmp_train_df, (1,10))\n",
    "# print \"sampling dataset =\", len(tmp_train_df)\n",
    "# print tmp_train_df[\"day\"].value_counts()\n",
    "\n",
    "# 抽样\n",
    "# tmp_train_df = tmp_train_df.sample(n=10000, random_state=666)\n",
    "# print \"sampling dataset =\", len(tmp_train_df)\n",
    "\n",
    "print(tmp_train_df[\"day\"].value_counts())\n",
    "\n",
    "#测试版\n",
    "# valid_df = tmp_train_df.loc[tmp_train_df[\"day\"]==6]\n",
    "# tmp_train_df = tmp_train_df.loc[tmp_train_df[\"day\"]<6]\n",
    "# # tmp_train_df = tmp_train_df.loc[tmp_train_df[\"day\"]>0]\n",
    "# res_df=valid_df.copy()\n",
    "\n",
    "# #线上验证版\n",
    "valid_df = tmp_train_df.loc[tmp_train_df[\"day\"]==6]\n",
    "res_df = tmp_train_df.loc[tmp_train_df[\"day\"]==7].copy()\n",
    "tmp_train_df = tmp_train_df.loc[tmp_train_df[\"day\"]<=6]\n",
    "#res_df = res_df.drop(['item_category_list', 'item_property_list', 'date'], axis=1)\n",
    "\n",
    "\n",
    "print(\"res dataset = %s\" % len(res_df))\n",
    "print(\"valid dateset = %s\" % len(valid_df))\n",
    "print(\"train dateset = %s\" % len(tmp_train_df))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "use_fea1=[  \n",
    "                'item_price_level',\n",
    "                'item_sales_level',\n",
    "                'item_collected_level',\n",
    "                'item_pv_level',\n",
    "                'user_gender_id',\n",
    "                'user_age_level',\n",
    "                'user_occupation_id',\n",
    "                'user_star_level',\n",
    "                'context_page_id',\n",
    "                'shop_review_num_level',\n",
    "                'shop_star_level',\n",
    "                \"weekday\",\n",
    "                \"hour\",\n",
    "    \n",
    "                'item_category_1',\n",
    "                'item_category_2',\n",
    "                \n",
    "#                 \"item_brand_id\",\n",
    "#                 \"item_city_id\",\n",
    "#                 \"item_id\",\n",
    "#                 \"shop_id\",\n",
    "    \n",
    "#                 \"item_review_cnt\",\n",
    "#                 \"cate_review_cnt\",\n",
    "                \n",
    "                'shop_review_positive_rate',\n",
    "                'shop_score_service',\n",
    "                'shop_score_delivery',\n",
    "                'shop_score_description'\n",
    "            ]\n",
    "\n",
    "use_fea2=[  \n",
    "                'item_price_level',\n",
    "                'item_sales_level',\n",
    "                'item_collected_level',\n",
    "                'item_pv_level',\n",
    "                'user_gender_id',\n",
    "                'user_age_level',\n",
    "                'user_occupation_id',\n",
    "                'user_star_level',\n",
    "                'context_page_id',\n",
    "                'shop_review_num_level',\n",
    "                'shop_star_level',\n",
    "                \"weekday\",\n",
    "                \"hour\",\n",
    "    \n",
    "                'item_category_1',\n",
    "                'item_category_2',\n",
    "                \n",
    "#                 \"item_brand_id\",\n",
    "#                 \"item_city_id\",\n",
    "#                 \"item_id\",\n",
    "#                 \"shop_id\",\n",
    "    \n",
    "                \"item_review_cnt\",\n",
    "                \"cate_review_cnt\",\n",
    "                \n",
    "                'shop_review_positive_rate',\n",
    "                'shop_score_service',\n",
    "                'shop_score_delivery',\n",
    "                'shop_score_description'\n",
    "            ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# tmp_train_df = tmp_train_df[on_cols]\n",
    "# valid_df = valid_df[on_cols]\n",
    "\n",
    "\n",
    "# on_cols = [target_col]+numerical_cols+categorical_one_hot_cols+listype_one_hot_cols\n",
    "# # on_cols = [target_col]+numerical_cols\n",
    "# # +categorical_one_hot_cols+listype_one_hot_cols\n",
    "# train_lls, test_lls = train_and_test_lr(tmp_train_df[on_cols], valid_df[on_cols], res_df[on_cols+[index_col]])\n",
    "# print(\"LR %s dimension TrainLogLoss = %s | TestLogLoss = %s\" % (len(tmp_train_df[on_cols].columns), train_lls, test_lls))\n",
    "\n",
    "\n",
    "\n",
    "# on_cols = [target_col]+categorical_cols+numerical_cols\n",
    "# # on_cols = [target_col]+select_best_features(tmp_train_df[on_cols], 0.8)\n",
    "# train_lls, test_lls = train_and_test_randomforest(tmp_train_df[on_cols], valid_df[on_cols], res_df[on_cols+[index_col]])\n",
    "# print(\"XGBoost %s dimension TrainLogLoss = %s | TestLogLoss = %s\" % (len(tmp_train_df[on_cols].columns), train_lls, test_lls))\n",
    "\n",
    "\n",
    "\n",
    "# on_cols = [target_col]+categorical_cols+numerical_cols\n",
    "# on_cols = [target_col]+select_best_features(tmp_train_df[on_cols], 0.95)\n",
    "# train_lls, test_lls = train_and_test_randomforest(tmp_train_df[on_cols], valid_df[on_cols], res_df[on_cols+[index_col]])\n",
    "# print(\"XGBoost %s dimension TrainLogLoss = %s | TestLogLoss = %s\" % (len(tmp_train_df[on_cols].columns), train_lls, test_lls))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# +listype_one_hot_cols\n",
    "# on_cols = ffea(on_cols)\n",
    "\n",
    "\n",
    "\n",
    "# use_fea = use_fea1\n",
    "# train_lls, test_lls = train_and_test_gbdt(tmp_train_df[use_fea+[target]], valid_df[use_fea+[target]], None)\n",
    "# print(\"GBDT %s dimension TrainLogLoss = %s | TestLogLoss = %s\" % (len(tmp_train_df[use_fea].columns), train_lls, test_lls))\n",
    "\n",
    "# use_fea = use_fea2\n",
    "# train_lls, test_lls = train_and_test_gbdt(tmp_train_df[use_fea+[target]], valid_df[use_fea+[target]], None)\n",
    "# print(\"GBDT %s dimension TrainLogLoss = %s | TestLogLoss = %s\" % (len(tmp_train_df[use_fea].columns), train_lls, test_lls))\n",
    "\n",
    "\n",
    "\n",
    "# use_fea = use_fea1\n",
    "# train_lls, test_lls = train_and_test_xgboost(tmp_train_df[use_fea+[target]], valid_df[use_fea+[target]], res_df[use_fea+[index_col]])\n",
    "# print(\"XGBoost %s dimension TrainLogLoss = %s | TestLogLoss = %s\" % (len(tmp_train_df[use_fea].columns), train_lls, test_lls))\n",
    "\n",
    "use_fea = use_fea2\n",
    "train_lls, test_lls = train_and_test_xgboost(tmp_train_df[use_fea+[target]], valid_df[use_fea+[target]], res_df[use_fea+[index_col]])\n",
    "print(\"XGBoost %s dimension TrainLogLoss = %s | TestLogLoss = %s\" % (len(tmp_train_df[use_fea].columns), train_lls, test_lls))\n",
    "\n",
    "\n",
    "\n",
    "# use_fea = use_fea1\n",
    "# train_lls, test_lls = train_and_test_randomforest(tmp_train_df[use_fea+[target]], valid_df[use_fea+[target]], res_df[use_fea+[index_col]])\n",
    "# print(\"RandomForest %s dimension TrainLogLoss = %s | TestLogLoss = %s\" % (len(tmp_train_df[use_fea].columns), train_lls, test_lls))\n",
    "\n",
    "use_fea = use_fea2\n",
    "train_lls, test_lls = train_and_test_randomforest(tmp_train_df[use_fea+[target]], valid_df[use_fea+[target]], res_df[use_fea+[index_col]])\n",
    "print(\"RandomForest %s dimension TrainLogLoss = %s | TestLogLoss = %s\" % (len(tmp_train_df[use_fea].columns), train_lls, test_lls))\n",
    "\n",
    "\n",
    "\n",
    "# on_cols = [target_col]+categorical_cols+numerical_cols+listype_one_hot_cols\n",
    "# train_lls, test_lls = train_and_test_gbdt(tmp_train_df[on_cols], valid_df[on_cols], res_df[on_cols+[index_col]])\n",
    "# print(\"GBDT %s dimension TrainLogLoss = %s | TestLogLoss = %s\" % (len(tmp_train_df[on_cols].columns), train_lls, test_lls))\n",
    "\n",
    "\n",
    "# train_lls, test_lls = train_and_test_combine(tmp_train_df[on_cols], valid_df[on_cols])\n",
    "# print \"Combine TrainLogLoss = %s | TestLogLoss = %s\" % (train_lls, test_lls)\n",
    "\n",
    "# on_cols = [target_col]+numerical_cols+categorical_one_hot_cols+listype_one_hot_cols\n",
    "# train_lls, test_lls = train_and_test_FFM(tmp_train_df, valid_df)\n",
    "# print \"FFM TrainLogLoss = %s | TestLogLoss = %s\" % (train_lls, test_lls)\n",
    "\n",
    "# train_lls, test_lls = train_and_test_FFM(tmp_train_df, valid_df, res_df)\n",
    "# print(\"LR %s dimension TrainLogLoss = %s | TestLogLoss = %s\" % (len(tmp_train_df[on_cols].columns), train_lls, test_lls))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- | XGboost | 增减 | LR |增减\n",
    "- | :-: | :-: | :-: | :-:\n",
    "原始特征 | 0.0829350458274 | / | 0.0829428179401 | /\n",
    "原始特征+时间 | 0.0828004994761 | +++ | 0.082869098617 | +\n",
    "同上+按天计算交易率 | 0.0828218434014 | - | 0.0827914564667 | ++\n",
    "同上+predict_prop_cate相似度 | 0.082778758021 | ++ | 0.082798919764 | --\n",
    "同上+cate prop丰富度 | 0.0828356414143 | -- | 0.0828009736655 | -\n",
    "同上+cate/prop list OneHot | 0.0828356414143 | / | 0.0827979171146 | +"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
