{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加上两个用户行为特征\n",
    "\n",
    "1. 8234 base\n",
    "2. n_estimators 91\n",
    "3. gamma 6.6\n",
    "4. max_depth_step 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "train_df = pd.read_table('../../round1_ijcai_18_train_20180301.txt',sep=' ')\n",
    "test_df = pd.read_table('../../round1_ijcai_18_test_a_20180301.txt',sep=' ')\n",
    "\n",
    "# 线下线上数据统一进行特征处理\n",
    "test_df['is_trade'] = -1\n",
    "total_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 先处理时序数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间处理: 分离天, 星期几, 上中下午/晚上, 小时数\n",
    "# date最终不使用，直接用day(第 0 - 7 天)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "def extract_date(x):\n",
    "    d = datetime.fromtimestamp(x)\n",
    "    return d.strftime('%Y-%m-%d')\n",
    "def extract_weekday(x):\n",
    "    d = datetime.fromtimestamp(x)\n",
    "    return d.weekday()\n",
    "def extract_hour(x):\n",
    "    d = datetime.fromtimestamp(x)\n",
    "    return d.hour\n",
    "\n",
    "total_df['date'] = total_df['context_timestamp'].apply(lambda x: extract_date(x))\n",
    "total_df['day'] = le.fit_transform(total_df['date'])\n",
    "total_df['weekday'] = total_df['context_timestamp'].apply(lambda x: extract_weekday(x))\n",
    "total_df['hour'] = total_df['context_timestamp'].apply(lambda x: extract_hour(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 先分离训练集, 测试集, 线上集\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420717,) (57421,)\n"
     ]
    }
   ],
   "source": [
    "# 获取训练测试的索引, 6全集数据验证, 7为生成上线文件\n",
    "import numpy as np\n",
    "test_day= 6\n",
    "starts = list(range(0,test_day))\n",
    "ends = [test_day]\n",
    "train_indices = total_df[total_df['day'].isin(starts)].index.values\n",
    "test_indices = total_df[total_df['day'].isin(ends)].index.values\n",
    "print(train_indices.shape, test_indices.shape)\n",
    "\n",
    "tmp_df = total_df.copy()\n",
    "\n",
    "# 把测试索引的label提取\n",
    "y_test = tmp_df.iloc[test_indices]['is_trade']\n",
    "\n",
    "# 把需要训练和测试的数据提取, 并且强制去掉测试集的label列\n",
    "tmp_df.loc[test_indices, 'is_trade'] = np.nan\n",
    "\n",
    "# 得出训练测试必须的数据集 ,并且添加一列data_set作为标记\n",
    "train_tmp = tmp_df.iloc[train_indices].copy()\n",
    "train_tmp['data_set'] = 'training'\n",
    "test_tmp = tmp_df.iloc[test_indices].copy()\n",
    "test_tmp['data_set'] = 'testing'\n",
    "raw_df = train_tmp.append(test_tmp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重复列特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../util/time_utils.py\n",
    "dup_feat = ['item_id', 'item_brand_id', 'shop_id', 'user_id']\n",
    "raw_df = generateColDupByDay(raw_df, dup_feat, list(range(1, 8)), verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交易率特征选择\n",
    "\n",
    "*固定smooth为10*\n",
    "\n",
    "1. 特征是否独立提升?\n",
    "2. 平滑是否不会改变正负向?\n",
    "\n",
    "##### 正向特征\n",
    "\n",
    "> item_city_id, shop_id, user_gender_id, item_sales_level, item_collected_level, shop_review_num_level\n",
    "\n",
    "##### 负向特征\n",
    "\n",
    "> item_price_level,\n",
    "item_id,item_brand_id,item_pv_level,user_age_level,\n",
    "user_occupation_id,user_star_level,context_page_id,\n",
    "shop_review_positive_rate,shop_star_level,\n",
    "shop_score_service,shop_score_description,day,hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:696: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(478138, 71)\n"
     ]
    }
   ],
   "source": [
    "# 计算前一天的交易率set到下一天，第0天用回自己\n",
    "# %run ../util/time_utils.py\n",
    "\n",
    "# setTradeRateByDate(raw_df, ['item_city_id', 'item_id', 'item_brand_id', 'shop_id', 'user_id'])\n",
    "\n",
    "# 计算前一天的交易率set到下一天，第0天用回自己\n",
    "%run ../util/trade_info.py\n",
    "\n",
    "# trade_rela = ['item_city_id', 'shop_id', 'user_gender_id', 'item_sales_level', 'item_collected_level', 'shop_review_num_level']\n",
    "trade_rela = ['item_city_id', 'item_id', 'item_brand_id', 'shop_id', 'user_id']\n",
    "\n",
    "# colSm = {}\n",
    "# for col in trade_rela:\n",
    "#     colSm[col] = [15*(mean0) , 15]\n",
    "generateTradeRateByDate(raw_df, trade_rela, 7, None, verbose=False, glbSmoothing=200, glbMean0=0.05)\n",
    "print(raw_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 复合类型拆解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_icl_map ... \n",
      "get_ipl_map ... \n",
      "processing predict_category_property ...\n",
      "processing item_property_list ...\n",
      "processing item_category_list ...\n",
      "generating item_category_1, item_category_2 ...\n"
     ]
    }
   ],
   "source": [
    "%run ../util/complex_type.py\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "le = preprocessing.LabelEncoder()\n",
    "raw_df = process_complex_types(raw_df, get_icl_map(raw_df), get_ipl_map(raw_df))\n",
    "\n",
    "raw_df['item_category_1'] = le.fit_transform(raw_df.item_category_1)\n",
    "raw_df['item_category_2'] = le.fit_transform(raw_df.item_category_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(478138, 77)\n"
     ]
    }
   ],
   "source": [
    "%run ../util/complex_type.py\n",
    "\n",
    "cnt_user_item_review = raw_df[[\"user_id\", \"item_id\", \"instance_id\"]].groupby([\"user_id\", \"item_id\"])['instance_id'].count().to_dict() \n",
    "cnt_user_cate_review = raw_df[[\"user_id\", \"item_category_1\", \"instance_id\"]].groupby([\"user_id\", \"item_category_1\"])['instance_id'].count().to_dict()  \n",
    "\n",
    "f1 = set_review_cnt(\"user_id\", \"item_id\", cnt_user_item_review)\n",
    "f2 = set_review_cnt(\"user_id\", \"item_category_1\", cnt_user_cate_review)\n",
    "\n",
    "tmp = raw_df.sort_values(by=\"context_timestamp\")\n",
    "tmp[\"item_review_cnt\"] = tmp[[\"user_id\", \"item_id\"]].apply(f1, axis=1)\n",
    "tmp[\"cate_review_cnt\"] = tmp[[\"user_id\", \"item_category_1\"]].apply(f2, axis=1)\n",
    "raw_df = tmp.sort_index()\n",
    "print(raw_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 生成矩阵数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420717, 1) (420717, 64) (420717,) (57421, 64) (57421,)\n"
     ]
    }
   ],
   "source": [
    "train_df = raw_df[raw_df['data_set'] == 'training']\n",
    "test_df = raw_df[raw_df['data_set'] == 'testing']\n",
    "\n",
    "non_feat_columns = ['data_set', 'context_timestamp', 'instance_id', 'is_trade', 'context_id',\n",
    "                   'item_property_list', 'item_category_list', 'date', 'predict_category_property',\n",
    "                    'predict_richness', 'predict_category_property', 'item_property_richness', 'item_property_list', \n",
    "                    'item_category_list', 'item_category_1', 'item_category_2'\n",
    "                   ]\n",
    "\n",
    "D = train_df[['date']]\n",
    "X_train = train_df.drop(non_feat_columns, axis=1)\n",
    "y_train = train_df[['is_trade']].values.ravel()\n",
    "X_test = test_df.drop(non_feat_columns, axis=1)\n",
    "# y_test is already exists\n",
    "\n",
    "# X_online = test_df.drop(non_feat_columns, axis=1).values\n",
    "print(D.shape, X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08160, b: 0.08063\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost\n",
    "\n",
    "#import lightgbm as lgb\n",
    "\n",
    "%run ../util/time_series_split.py\n",
    "\n",
    "# clf = lgb.LGBMClassifier(n_jobs=20)\n",
    "clf = xgboost.XGBClassifier(n_jobs=7,max_depth=5,n_estimators=91,min_child_weight=5, scale_pos_weight=1)\n",
    "# clf = xgboost.XGBClassifier(n_jobs=7, max_depth=3, n_estimators=230)\n",
    "\n",
    "m = None\n",
    "\n",
    "# 如果移动到线上集, 则输出模型\n",
    "if sum(y_test == -1) > 0:\n",
    "    m = clf.fit(X_train, y_train)\n",
    "    result = pd.DataFrame()\n",
    "    result['instance_id'] = test_df['instance_id']\n",
    "    result['predicted_score'] = pd.DataFrame(m.predict_proba(X_test))[1].values\n",
    "    result.to_csv('submits/6_7379_8092_a8160_b8063.csv', sep = ' ', header=True, index = False)\n",
    "else:\n",
    "    # 分离a,b榜\n",
    "    X_val_a, X_val_b, y_val_a, y_val_b = train_test_split(X_test, y_test, test_size=0.7, shuffle=True, random_state=6)\n",
    "    m = clf.fit(X_train, y_train)\n",
    "    \n",
    "    val_a_loss = log_loss(y_val_a, m.predict_proba(X_val_a))\n",
    "    val_b_loss = log_loss(y_val_b, m.predict_proba(X_val_b))\n",
    "    print('(%s -> %s) train logloss: %.5f, test logloss: %.5f, a: %.5f, b: %.5f' % \\\n",
    "          (starts, ends, \\\n",
    "           log_loss(y_train, m.predict_proba(X_train)), \\\n",
    "           log_loss(y_test, m.predict_proba(X_test)),\\\n",
    "          val_a_loss, val_b_loss))\n",
    "    \n",
    "# ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07348, test logloss: 0.08093, a: 0.08162, b: 0.08064\n",
    "# ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08160, b: 0.08063\n",
    "# ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07424, test logloss: 0.08098, a: 0.08179, b: 0.08064"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08471, b: 0.07930\n",
      "1 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07699, b: 0.08261\n",
      "2 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08371, b: 0.07973\n",
      "3 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08037, b: 0.08116\n",
      "4 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07783, b: 0.08225\n",
      "5 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08447, b: 0.07940\n",
      "6 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08160, b: 0.08063\n",
      "7 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08499, b: 0.07918\n",
      "8 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07788, b: 0.08223\n",
      "9 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08523, b: 0.07908\n",
      "10 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08545, b: 0.07898\n",
      "11 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07737, b: 0.08244\n",
      "12 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07781, b: 0.08226\n",
      "13 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07525, b: 0.08335\n",
      "14 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08486, b: 0.07924\n",
      "15 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07491, b: 0.08350\n",
      "16 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08007, b: 0.08129\n",
      "17 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07819, b: 0.08210\n",
      "18 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08408, b: 0.07957\n",
      "19 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08389, b: 0.07965\n",
      "20 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08387, b: 0.07966\n",
      "21 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08291, b: 0.08007\n",
      "22 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08057, b: 0.08108\n",
      "23 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08021, b: 0.08123\n",
      "24 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08412, b: 0.07955\n",
      "25 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07899, b: 0.08175\n",
      "26 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08203, b: 0.08045\n",
      "27 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08029, b: 0.08120\n",
      "28 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08268, b: 0.08017\n",
      "29 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08385, b: 0.07967\n",
      "30 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08281, b: 0.08011\n",
      "31 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07899, b: 0.08175\n",
      "32 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07773, b: 0.08229\n",
      "33 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08276, b: 0.08014\n",
      "34 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08133, b: 0.08075\n",
      "35 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07488, b: 0.08351\n",
      "36 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07758, b: 0.08236\n",
      "37 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08239, b: 0.08030\n",
      "38 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07747, b: 0.08240\n",
      "39 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08325, b: 0.07992\n",
      "40 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07690, b: 0.08265\n",
      "41 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07858, b: 0.08193\n",
      "42 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08333, b: 0.07989\n",
      "43 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07730, b: 0.08248\n",
      "44 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08303, b: 0.08002\n",
      "45 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07973, b: 0.08144\n",
      "46 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07967, b: 0.08146\n",
      "47 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08044, b: 0.08113\n",
      "48 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07698, b: 0.08261\n",
      "49 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08095, b: 0.08091\n",
      "50 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08203, b: 0.08045\n",
      "51 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07910, b: 0.08171\n",
      "52 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08195, b: 0.08048\n",
      "53 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08155, b: 0.08065\n",
      "54 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08193, b: 0.08049\n",
      "55 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08336, b: 0.07988\n",
      "56 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07764, b: 0.08233\n",
      "57 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08470, b: 0.07930\n",
      "58 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08047, b: 0.08112\n",
      "59 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07825, b: 0.08207\n",
      "60 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07974, b: 0.08143\n",
      "61 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07940, b: 0.08158\n",
      "62 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08147, b: 0.08069\n",
      "63 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08362, b: 0.07977\n",
      "64 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07885, b: 0.08181\n",
      "65 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08287, b: 0.08009\n",
      "66 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07560, b: 0.08320\n",
      "67 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08109, b: 0.08085\n",
      "68 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08279, b: 0.08012\n",
      "69 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08136, b: 0.08073\n",
      "70 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08179, b: 0.08055\n",
      "71 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08146, b: 0.08069\n",
      "72 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08179, b: 0.08055\n",
      "73 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07863, b: 0.08191\n",
      "74 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08330, b: 0.07990\n",
      "75 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08355, b: 0.07980\n",
      "76 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08378, b: 0.07970\n",
      "77 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08082, b: 0.08097\n",
      "78 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07763, b: 0.08234\n",
      "79 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08293, b: 0.08006\n",
      "80 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07954, b: 0.08152\n",
      "81 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07852, b: 0.08195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08022, b: 0.08123\n",
      "83 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08380, b: 0.07969\n",
      "84 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08005, b: 0.08130\n",
      "85 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08006, b: 0.08129\n",
      "86 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07668, b: 0.08274\n",
      "87 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08496, b: 0.07919\n",
      "88 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08388, b: 0.07966\n",
      "89 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07768, b: 0.08231\n",
      "90 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08080, b: 0.08098\n",
      "91 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07724, b: 0.08250\n",
      "92 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07854, b: 0.08194\n",
      "93 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08123, b: 0.08079\n",
      "94 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07911, b: 0.08170\n",
      "95 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08093, b: 0.08092\n",
      "96 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08105, b: 0.08087\n",
      "97 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08169, b: 0.08059\n",
      "98 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08234, b: 0.08031\n",
      "99 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08031, b: 0.08118\n",
      "100 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07554, b: 0.08323\n",
      "101 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08093, b: 0.08092\n",
      "102 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07946, b: 0.08155\n",
      "103 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07974, b: 0.08143\n",
      "104 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08103, b: 0.08088\n",
      "105 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08361, b: 0.07977\n",
      "106 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08284, b: 0.08010\n",
      "107 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08152, b: 0.08067\n",
      "108 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07789, b: 0.08222\n",
      "109 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07751, b: 0.08238\n",
      "110 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07962, b: 0.08148\n",
      "111 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07654, b: 0.08280\n",
      "112 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07615, b: 0.08297\n",
      "113 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07758, b: 0.08235\n",
      "114 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07978, b: 0.08141\n",
      "115 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08266, b: 0.08018\n",
      "116 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08881, b: 0.07754\n",
      "117 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08359, b: 0.07978\n",
      "118 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07751, b: 0.08238\n",
      "119 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08322, b: 0.07994\n",
      "120 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08000, b: 0.08132\n",
      "121 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08096, b: 0.08091\n",
      "122 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07877, b: 0.08184\n",
      "123 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08020, b: 0.08123\n",
      "124 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08217, b: 0.08039\n",
      "125 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08081, b: 0.08097\n",
      "126 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08520, b: 0.07909\n",
      "127 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07788, b: 0.08223\n",
      "128 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07867, b: 0.08189\n",
      "129 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07693, b: 0.08264\n",
      "130 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07951, b: 0.08153\n",
      "131 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08651, b: 0.07853\n",
      "132 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08790, b: 0.07793\n",
      "133 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08681, b: 0.07840\n",
      "134 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08113, b: 0.08083\n",
      "135 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07645, b: 0.08284\n",
      "136 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07793, b: 0.08220\n",
      "137 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07901, b: 0.08174\n",
      "138 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08081, b: 0.08097\n",
      "139 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08391, b: 0.07964\n",
      "140 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08244, b: 0.08027\n",
      "141 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08092, b: 0.08092\n",
      "142 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08032, b: 0.08118\n",
      "143 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08112, b: 0.08084\n",
      "144 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08021, b: 0.08123\n",
      "145 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08666, b: 0.07846\n",
      "146 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07575, b: 0.08314\n",
      "147 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07845, b: 0.08198\n",
      "148 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08098, b: 0.08090\n",
      "149 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08275, b: 0.08014\n",
      "150 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08437, b: 0.07945\n",
      "151 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08188, b: 0.08051\n",
      "152 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08592, b: 0.07878\n",
      "153 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07926, b: 0.08164\n",
      "154 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07678, b: 0.08270\n",
      "155 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07901, b: 0.08174\n",
      "156 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08029, b: 0.08120\n",
      "157 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08647, b: 0.07855\n",
      "158 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08509, b: 0.07914\n",
      "159 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08106, b: 0.08087\n",
      "160 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08023, b: 0.08122\n",
      "161 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08390, b: 0.07965\n",
      "162 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08332, b: 0.07989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07556, b: 0.08322\n",
      "164 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08388, b: 0.07965\n",
      "165 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08104, b: 0.08087\n",
      "166 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07920, b: 0.08166\n",
      "167 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08256, b: 0.08022\n",
      "168 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08185, b: 0.08053\n",
      "169 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08108, b: 0.08086\n",
      "170 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07944, b: 0.08156\n",
      "171 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08395, b: 0.07963\n",
      "172 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08373, b: 0.07972\n",
      "173 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08466, b: 0.07932\n",
      "174 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08219, b: 0.08038\n",
      "175 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08574, b: 0.07886\n",
      "176 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07775, b: 0.08228\n",
      "177 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08284, b: 0.08010\n",
      "178 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07896, b: 0.08177\n",
      "179 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08005, b: 0.08130\n",
      "180 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08164, b: 0.08062\n",
      "181 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08329, b: 0.07991\n",
      "182 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08264, b: 0.08019\n",
      "183 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07943, b: 0.08156\n",
      "184 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08323, b: 0.07993\n",
      "185 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08499, b: 0.07918\n",
      "186 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07546, b: 0.08326\n",
      "187 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07853, b: 0.08195\n",
      "188 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08107, b: 0.08086\n",
      "189 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08830, b: 0.07776\n",
      "190 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07927, b: 0.08163\n",
      "191 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07834, b: 0.08203\n",
      "192 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08336, b: 0.07988\n",
      "193 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08243, b: 0.08028\n",
      "194 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08272, b: 0.08015\n",
      "195 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08393, b: 0.07963\n",
      "196 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08164, b: 0.08061\n",
      "197 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07745, b: 0.08241\n",
      "198 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07558, b: 0.08321\n",
      "199 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07908, b: 0.08171\n",
      "200 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08161, b: 0.08063\n",
      "201 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07870, b: 0.08188\n",
      "202 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07818, b: 0.08210\n",
      "203 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08180, b: 0.08055\n",
      "204 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08291, b: 0.08007\n",
      "205 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08326, b: 0.07992\n",
      "206 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08071, b: 0.08101\n",
      "207 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08642, b: 0.07857\n",
      "208 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08617, b: 0.07867\n",
      "209 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07886, b: 0.08180\n",
      "210 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08339, b: 0.07987\n",
      "211 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08243, b: 0.08028\n",
      "212 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08024, b: 0.08122\n",
      "213 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08365, b: 0.07976\n",
      "214 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07577, b: 0.08313\n",
      "215 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07814, b: 0.08211\n",
      "216 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08468, b: 0.07931\n",
      "217 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08579, b: 0.07884\n",
      "218 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08211, b: 0.08041\n",
      "219 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07963, b: 0.08148\n",
      "220 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07915, b: 0.08168\n",
      "221 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07885, b: 0.08181\n",
      "222 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08207, b: 0.08043\n",
      "223 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07593, b: 0.08306\n",
      "224 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08023, b: 0.08122\n",
      "225 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07914, b: 0.08169\n",
      "226 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07697, b: 0.08262\n",
      "227 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08015, b: 0.08125\n",
      "228 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08030, b: 0.08119\n",
      "229 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07664, b: 0.08276\n",
      "230 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08358, b: 0.07978\n",
      "231 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08292, b: 0.08007\n",
      "232 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08103, b: 0.08088\n",
      "233 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08319, b: 0.07995\n",
      "234 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08560, b: 0.07892\n",
      "235 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08317, b: 0.07996\n",
      "236 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08301, b: 0.08003\n",
      "237 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07773, b: 0.08229\n",
      "238 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08906, b: 0.07744\n",
      "239 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08581, b: 0.07883\n",
      "240 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07877, b: 0.08185\n",
      "241 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08384, b: 0.07967\n",
      "242 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08558, b: 0.07893\n",
      "243 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08135, b: 0.08074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08141, b: 0.08071\n",
      "245 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07742, b: 0.08243\n",
      "246 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08260, b: 0.08020\n",
      "247 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07936, b: 0.08159\n",
      "248 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07839, b: 0.08201\n",
      "249 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08625, b: 0.07864\n",
      "250 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08076, b: 0.08099\n",
      "251 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08048, b: 0.08111\n",
      "252 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08319, b: 0.07995\n",
      "253 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07817, b: 0.08210\n",
      "254 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07926, b: 0.08163\n",
      "255 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08211, b: 0.08041\n",
      "256 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07808, b: 0.08214\n",
      "257 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08384, b: 0.07967\n",
      "258 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08033, b: 0.08118\n",
      "259 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08137, b: 0.08073\n",
      "260 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08546, b: 0.07898\n",
      "261 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08121, b: 0.08080\n",
      "262 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08020, b: 0.08123\n",
      "263 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07518, b: 0.08339\n",
      "264 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07460, b: 0.08363\n",
      "265 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08295, b: 0.08006\n",
      "266 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07942, b: 0.08157\n",
      "267 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07725, b: 0.08250\n",
      "268 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08400, b: 0.07961\n",
      "269 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07813, b: 0.08212\n",
      "270 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07495, b: 0.08348\n",
      "271 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07364, b: 0.08404\n",
      "272 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07986, b: 0.08138\n",
      "273 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08147, b: 0.08069\n",
      "274 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08329, b: 0.07991\n",
      "275 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08161, b: 0.08063\n",
      "276 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08230, b: 0.08033\n",
      "277 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07561, b: 0.08320\n",
      "278 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07768, b: 0.08231\n",
      "279 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08593, b: 0.07878\n",
      "280 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08203, b: 0.08045\n",
      "281 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08272, b: 0.08015\n",
      "282 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08142, b: 0.08071\n",
      "283 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08031, b: 0.08119\n",
      "284 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07732, b: 0.08247\n",
      "285 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08147, b: 0.08069\n",
      "286 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08256, b: 0.08022\n",
      "287 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08285, b: 0.08010\n",
      "288 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07664, b: 0.08276\n",
      "289 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07724, b: 0.08250\n",
      "290 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07863, b: 0.08190\n",
      "291 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08000, b: 0.08132\n",
      "292 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08049, b: 0.08111\n",
      "293 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08211, b: 0.08041\n",
      "294 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07895, b: 0.08177\n",
      "295 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08346, b: 0.07983\n",
      "296 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08200, b: 0.08046\n",
      "297 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07514, b: 0.08340\n",
      "298 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08499, b: 0.07918\n",
      "299 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07707, b: 0.08257\n",
      "300 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08011, b: 0.08127\n",
      "301 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08067, b: 0.08103\n",
      "302 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08411, b: 0.07956\n",
      "303 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08232, b: 0.08032\n",
      "304 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08152, b: 0.08067\n",
      "305 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08130, b: 0.08076\n",
      "306 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08543, b: 0.07899\n",
      "307 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08017, b: 0.08125\n",
      "308 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08539, b: 0.07901\n",
      "309 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07751, b: 0.08239\n",
      "310 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07831, b: 0.08204\n",
      "311 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07634, b: 0.08289\n",
      "312 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07509, b: 0.08342\n",
      "313 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08039, b: 0.08115\n",
      "314 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07910, b: 0.08170\n",
      "315 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07987, b: 0.08137\n",
      "316 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07454, b: 0.08366\n",
      "317 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08549, b: 0.07897\n",
      "318 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08888, b: 0.07751\n",
      "319 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07919, b: 0.08167\n",
      "320 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08560, b: 0.07892\n",
      "321 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08261, b: 0.08020\n",
      "322 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07809, b: 0.08214\n",
      "323 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07892, b: 0.08178\n",
      "324 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08219, b: 0.08038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07668, b: 0.08274\n",
      "326 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08378, b: 0.07970\n",
      "327 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08283, b: 0.08010\n",
      "328 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07943, b: 0.08156\n",
      "329 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08128, b: 0.08077\n",
      "330 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07931, b: 0.08161\n",
      "331 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08227, b: 0.08034\n",
      "332 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08216, b: 0.08039\n",
      "333 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07917, b: 0.08168\n",
      "334 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08209, b: 0.08042\n",
      "335 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08512, b: 0.07912\n",
      "336 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08415, b: 0.07954\n",
      "337 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07725, b: 0.08250\n",
      "338 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07719, b: 0.08252\n",
      "339 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08108, b: 0.08085\n",
      "340 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07999, b: 0.08132\n",
      "341 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08236, b: 0.08031\n",
      "342 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08509, b: 0.07914\n",
      "343 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07280, b: 0.08440\n",
      "344 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08453, b: 0.07938\n",
      "345 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08804, b: 0.07787\n",
      "346 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07999, b: 0.08132\n",
      "347 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.07913, b: 0.08169\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-94edcf3e2cea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mval_a_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mval_b_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%d (%s -> %s) train logloss: %.5f, test logloss: %.5f, a: %.5f, b: %.5f'\u001b[0m \u001b[1;33m%\u001b[0m           \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstarts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mends\u001b[0m\u001b[1;33m,\u001b[0m            \u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m            \u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m          \u001b[0mval_a_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_b_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\xgboost-0.7-py3.6.egg\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, data, output_margin, ntree_limit)\u001b[0m\n\u001b[0;32m    573\u001b[0m         class_probs = self.get_booster().predict(test_dmatrix,\n\u001b[0;32m    574\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m                                                  ntree_limit=ntree_limit)\n\u001b[0m\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"multi:softprob\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mclass_probs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\xgboost-0.7-py3.6.egg\\xgboost\\core.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions)\u001b[0m\n\u001b[0;32m   1056\u001b[0m                                           \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_uint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m                                           \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1058\u001b[1;33m                                           ctypes.byref(preds)))\n\u001b[0m\u001b[0;32m   1059\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes2numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    # 分离a,b榜\n",
    "    X_val_a, X_val_b, y_val_a, y_val_b = train_test_split(X_test, y_test, test_size=0.7, shuffle=True, random_state=i)\n",
    "    \n",
    "    val_a_loss = log_loss(y_val_a, m.predict_proba(X_val_a))\n",
    "    val_b_loss = log_loss(y_val_b, m.predict_proba(X_val_b))\n",
    "    print('%d (%s -> %s) train logloss: %.5f, test logloss: %.5f, a: %.5f, b: %.5f' % \\\n",
    "          (i, starts, ends, \\\n",
    "           log_loss(y_train, m.predict_proba(X_train)), \\\n",
    "           log_loss(y_test, m.predict_proba(X_test)),\\\n",
    "          val_a_loss, val_b_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 超参搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "params={\n",
    "    'max_depth': [5],#[6,10,15,20], # 5 is good but takes too long in kaggle env\n",
    "    'subsample': [1],#[1,0.9,0.8,0.7],#[0.1,0.2,0.3,0.4,0.5,0.55,0.6,0.65,0.7,0.8,0.9],#[0.9]\n",
    "    'colsample_bytree': [1],#[0.1,0.2,0.3,0.4,0.5,0.6,0.65,0.7,0.75,0.8,0.9,0.95],#[0.9],\n",
    "    'colsample_bylevel':[1],#[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "    'scale_pos_weight':[1],#[0.7,0.8,1,1.1,1.2],#0.1,0.5,1,2,5\n",
    "    'max_delta_step':[1,0.9,0.8,0.7],#[0,0.1,0.001,0.05,0.005,0.5,1,2],\n",
    "    'n_estimators': [91],#[100,90,91,92,93,94,95,96,97,98,99],#[200,230,260,270,280,290,300]\n",
    "    'reg_lambda': [1],#[1.3,1.4,1.5,1.6],\n",
    "    'reg_alpha': [0],#[0,0.01,0.1,0.02,0.2],#[0.01,0.05,0.005,0.2,0.1,0.02,0.0001,0],#\n",
    "    'min_child_weight':[5],#[7,8,9,10,11,12,13,14,15,16,17,18,19,20],#[23],#[20,21,22,23,24,25,26],#\n",
    "    'gamma':[0],#[6],#[0.1],#\n",
    "    'learning_rate':[0.1],#[0.01,0.015,0.02,0.025,0.05,0.005,0.1],#[0.02]#\n",
    "    \n",
    "}\n",
    "\n",
    "# if sum(y_test == -1) == 0:\n",
    "#     xgb = xgboost.XGBClassifier(n_jobs=7)\n",
    "#     best_score = 1 \n",
    "#     for g in ParameterGrid(params):\n",
    "#         xgb.set_params(**g)\n",
    "\n",
    "#         # 分离a,b榜\n",
    "#         X_val_a, X_val_b, y_val_a, y_val_b = train_test_split(X_test, y_test, test_size=0.7, shuffle=True, random_state=6)\n",
    "#         m = xgb.fit(X_train, y_train, eval_metric='logloss')\n",
    "\n",
    "#         val_train_loss = log_loss(y_train, m.predict_proba(X_train))\n",
    "#         val_test_loss = log_loss(y_test, m.predict_proba(X_test))\n",
    "#         val_a_loss = log_loss(y_val_a, m.predict_proba(X_val_a))\n",
    "#         val_b_loss = log_loss(y_val_b, m.predict_proba(X_val_b))\n",
    "#         print('-'*80)\n",
    "#         print(g)\n",
    "#         print('(%s -> %s) train logloss: %.5f, test logloss: %.5f, a: %.5f, b: %.5f' % \\\n",
    "#               (starts, ends, val_train_loss, val_test_loss, val_a_loss, val_b_loss))\n",
    "\n",
    "#         # save if best\n",
    "#         if val_test_loss < best_score:\n",
    "#             best_score = val_test_loss\n",
    "#             best_grid = g\n",
    "\n",
    "#     print('-'*80, '\\n')        \n",
    "#     print (\"log loss: %0.5f\" % best_score )\n",
    "#     print (\"Grid:\", best_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-03 08:02:07.632618\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
