{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载基本库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuhua/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.19.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import ffm\n",
    "import time\n",
    "# from sklearn import ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# import lightgbm as lgb\n",
    "from sklearn.metrics import log_loss\n",
    "import xgboost\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'instance_id', u'item_id', u'item_category_list',\n",
       "       u'item_property_list', u'item_brand_id', u'item_city_id',\n",
       "       u'item_price_level', u'item_sales_level', u'item_collected_level',\n",
       "       u'item_pv_level', u'user_id', u'user_gender_id', u'user_age_level',\n",
       "       u'user_occupation_id', u'user_star_level', u'context_id',\n",
       "       u'context_timestamp', u'context_page_id', u'predict_category_property',\n",
       "       u'shop_id', u'shop_review_num_level', u'shop_review_positive_rate',\n",
       "       u'shop_star_level', u'shop_score_service', u'shop_score_delivery',\n",
       "       u'shop_score_description', u'is_trade'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_table('/Users/yuhua/先验CTR模型线上观察/Alimama比赛/round1_ijcai_18_train_20180301.txt',sep=' ')\n",
    "test_df = pd.read_table('/Users/yuhua/先验CTR模型线上观察/Alimama比赛/round1_ijcai_18_test_a_20180301.txt',sep=' ')\n",
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run FeatureProcess.py\n",
    "featProc = FeatureProcess(   target=\"is_trade\", \n",
    "\n",
    "                            categorical=[  \n",
    "                                            'shop_id',\n",
    "                                            'item_brand_id',\n",
    "                                            'item_city_id',\n",
    "                                            'item_price_level',\n",
    "                                            'item_sales_level',\n",
    "                                            'item_collected_level',\n",
    "                                            'item_pv_level',\n",
    "                                            'user_gender_id',\n",
    "                                            'user_age_level',\n",
    "                                            'user_occupation_id',\n",
    "                                            'user_star_level',\n",
    "                                            'context_page_id',\n",
    "                                            'shop_review_num_level',\n",
    "                                            'shop_star_level'], \n",
    "\n",
    "                            numerical=[     'shop_review_positive_rate',\n",
    "                                            'shop_score_service',\n",
    "                                            'shop_score_delivery',\n",
    "                                            'shop_score_description']\n",
    "                                )\n",
    "\n",
    "#train_df = featProc.fillempty(train_df, -0.000000000001)\n",
    "#df = featProc.toOneHot(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_test_xgboost(train_df, test_df):\n",
    "    X_train = train_df.copy()\n",
    "    del X_train['is_trade']\n",
    "    y_train = train_df['is_trade']\n",
    "    \n",
    "    X_test = test_df.copy()\n",
    "    del X_test['is_trade']\n",
    "    y_test = test_df['is_trade']\n",
    "    \n",
    "    xgb = xgboost.XGBClassifier(nthread=20)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    \n",
    "    return log_loss(y_test,xgb.predict_proba(X_test))\n",
    "\n",
    "def train_and_test_lr(train_df, test_df):\n",
    "    X_train = train_df.copy()\n",
    "    del X_train['is_trade']\n",
    "    y_train = train_df['is_trade']\n",
    "    \n",
    "    X_test = test_df.copy()\n",
    "    del X_test['is_trade']\n",
    "    y_test = test_df['is_trade']\n",
    "    \n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    return log_loss(y_test,lr.predict_proba(X_test))\n",
    "\n",
    "def train_and_test_randomforest(train_df, test_df):\n",
    "    X_train = train_df.copy()\n",
    "    del X_train['is_trade']\n",
    "    y_train = train_df['is_trade']\n",
    "    \n",
    "    X_test = test_df.copy()\n",
    "    del X_test['is_trade']\n",
    "    y_test = test_df['is_trade']\n",
    "    \n",
    "#     rf = RandomForestClassifier(n_estimators=32, max_depth=40, min_samples_split=100, min_samples_leaf=10,  criterion='entropy',\n",
    "#                         max_features=8, verbose = 1,  bootstrap=False, n_jobs=10)\n",
    "#     RandomForestClassifier(criterion='entropy',n_estimators=100,n_jobs=15)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=32, max_depth=20, min_samples_split=100, min_samples_leaf=10,  criterion='entropy', max_features=8, verbose = 1,  bootstrap=False)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    return log_loss(y_test,rf.predict_proba(X_test))\n",
    "\n",
    "def train_and_test_gbdt(train_df, test_df):\n",
    "    X_train = train_df.copy()\n",
    "    del X_train['is_trade']\n",
    "    y_train = train_df['is_trade']\n",
    "    \n",
    "    X_test = test_df.copy()\n",
    "    del X_test['is_trade']\n",
    "    y_test = test_df['is_trade']\n",
    "    \n",
    "    gbdt = GradientBoostingClassifier()\n",
    "    gbdt.fit(X_train, y_train)\n",
    "    \n",
    "    return log_loss(y_test,gbdt.predict_proba(X_test))\n",
    "\n",
    "def train_and_test_gbdt(train_df, test_df):\n",
    "    X_train = train_df.copy()\n",
    "    del X_train['is_trade']\n",
    "    y_train = train_df['is_trade']\n",
    "    \n",
    "    X_test = test_df.copy()\n",
    "    del X_test['is_trade']\n",
    "    y_test = test_df['is_trade']\n",
    "    \n",
    "    gbdt = GradientBoostingClassifier()\n",
    "    gbdt.fit(X_train, y_train)\n",
    "    \n",
    "    return log_loss(y_test,gbdt.predict_proba(X_test))\n",
    "\n",
    "def train_and_test_ffm(train_df, test_df):\n",
    "#     X_train = train_df.copy()\n",
    "#     del X_train['is_trade']\n",
    "#     y_train = train_df['is_trade']\n",
    "    \n",
    "#     X_test = test_df.copy()\n",
    "#     del X_test['is_trade']\n",
    "#     y_test = test_df['is_trade']\n",
    "    \n",
    "    \n",
    "#     X_train = [tuple(x) for x in X_train.values]\n",
    "#     y_train = [y for y in y_train.values]\n",
    "    \n",
    "    \n",
    "    \n",
    "#     print \"train_df to FFM length =\", len(train_df)\n",
    "#     ffm_train = ffm.FFMData(featProc.cacheRun(featProc.toFFMData, train_df))\n",
    "    \n",
    "    print \"test_df to FFM length =\", len(test_df)\n",
    "    ffm_test = ffm.FFMData(featProc.cacheRun(featProc.toFFMData, test_df))\n",
    "    \n",
    "#     print \"start training ...\"\n",
    "#     model = ffm.FFM(eta=0.1, lam=0.0001, k=4)\n",
    "#     model.init_model(ffm_train)\n",
    "\n",
    "#     y_pred = model.predict_proba(ffm_test)\n",
    "    \n",
    "#     lls = log_loss(y_pred,gbdt.predict_proba(X_test))\n",
    "#     print \"lls =\",lls\n",
    "#     return lls\n",
    "    return 0\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffm= training and testing ...\n",
      "Doing 0 1  train_len=45424 test_len=23907\n",
      "test_df to FFM length = 23907\n",
      "From Cache ...\n"
     ]
    }
   ],
   "source": [
    "%run BaseFrame.py\n",
    "\n",
    "# tat = BaseFrame(train_df, 0.05,'context_timestamp', True)\n",
    "# print \"xgboost=\",tat.kflod_validation_seq(10,train_and_test_xgboost)\n",
    "\n",
    "# tat = BaseFrame(train_df, 0.05,'context_timestamp', True)\n",
    "# print \"lr=\",tat.kflod_validation_seq(10,train_and_test_lr)\n",
    "\n",
    "# tat = BaseFrame(train_df, 0.05,'context_timestamp', True)\n",
    "# print \"randomforest=\",tat.kflod_validation_seq(10,train_and_test_randomforest)\n",
    "\n",
    "# tat = BaseFrame(train_df, 0.05,'context_timestamp', True)\n",
    "# print \"gbdt=\",tat.kflod_validation_seq(10,train_and_test_gbdt)\n",
    "\n",
    "tat = BaseFrame(train_df, 0.05,'context_timestamp', True)\n",
    "print \"ffm=\",tat.kflod_validation_seq(10,train_and_test_ffm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# t1 = time.time()\n",
    "# df = train_df[0:1002]\n",
    "# df = featProc.fillempty(df, -0.000000000001)\n",
    "# # print \"LLLLLen=\", len(featProc.cacheRun(featProc.toFFMData, df).columns)\n",
    "\n",
    "# print len(featProc.cacheRun(featProc.toFFMData, df)[0])\n",
    "\n",
    "# print time.time() - t1\n",
    "\n",
    "# dir(train_df[\"item_id\"])\n",
    "import pickle,ffm\n",
    "f = ffm.FFMData(pickle.load(open(\"d25f691b0a6dfaf67971b243ae450999-toFFMData.pickle\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
