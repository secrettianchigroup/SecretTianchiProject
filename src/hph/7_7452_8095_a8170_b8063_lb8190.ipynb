{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加上两个用户行为特征\n",
    "\n",
    "*添加用户行为特征，对于item和分类的访问次数*\n",
    "\n",
    "*超参搜索，找出不容易过拟合的参数*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "train_df = pd.read_table('../../round1_ijcai_18_train_20180301.txt',sep=' ')\n",
    "test_df = pd.read_table('../../round1_ijcai_18_test_a_20180301.txt',sep=' ')\n",
    "\n",
    "# 线下线上数据统一进行特征处理\n",
    "test_df['is_trade'] = -1\n",
    "total_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 先处理时序数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间处理: 分离天, 星期几, 上中下午/晚上, 小时数\n",
    "# date最终不使用，直接用day(第 0 - 7 天)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "def extract_date(x):\n",
    "    d = datetime.fromtimestamp(x)\n",
    "    return d.strftime('%Y-%m-%d')\n",
    "def extract_weekday(x):\n",
    "    d = datetime.fromtimestamp(x)\n",
    "    return d.weekday()\n",
    "def extract_hour(x):\n",
    "    d = datetime.fromtimestamp(x)\n",
    "    return d.hour\n",
    "\n",
    "total_df['date'] = total_df['context_timestamp'].apply(lambda x: extract_date(x))\n",
    "total_df['day'] = le.fit_transform(total_df['date'])\n",
    "total_df['weekday'] = total_df['context_timestamp'].apply(lambda x: extract_weekday(x))\n",
    "total_df['hour'] = total_df['context_timestamp'].apply(lambda x: extract_hour(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 先分离训练集, 测试集, 线上集\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420717,) (57421,)\n"
     ]
    }
   ],
   "source": [
    "# 获取训练测试的索引, 6全集数据验证, 7为生成上线文件\n",
    "import numpy as np\n",
    "test_day= 6\n",
    "starts = list(range(0,test_day))\n",
    "ends = [test_day]\n",
    "train_indices = total_df[total_df['day'].isin(starts)].index.values\n",
    "test_indices = total_df[total_df['day'].isin(ends)].index.values\n",
    "print(train_indices.shape, test_indices.shape)\n",
    "\n",
    "tmp_df = total_df.copy()\n",
    "\n",
    "# 把测试索引的label提取\n",
    "y_test = tmp_df.iloc[test_indices]['is_trade']\n",
    "\n",
    "# 把需要训练和测试的数据提取, 并且强制去掉测试集的label列\n",
    "tmp_df.loc[test_indices, 'is_trade'] = np.nan\n",
    "\n",
    "# 得出训练测试必须的数据集 ,并且添加一列data_set作为标记\n",
    "train_tmp = tmp_df.iloc[train_indices].copy()\n",
    "train_tmp['data_set'] = 'training'\n",
    "test_tmp = tmp_df.iloc[test_indices].copy()\n",
    "test_tmp['data_set'] = 'testing'\n",
    "raw_df = train_tmp.append(test_tmp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重复列特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../util/time_utils.py\n",
    "dup_feat = ['item_id', 'item_brand_id', 'shop_id', 'user_id']\n",
    "raw_df = generateColDupByDay(raw_df, dup_feat, list(range(1, 8)), verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交易率特征选择\n",
    "\n",
    "*固定smooth为10*\n",
    "\n",
    "1. 特征是否独立提升?\n",
    "2. 平滑是否不会改变正负向?\n",
    "\n",
    "##### 正向特征\n",
    "\n",
    "> item_city_id, shop_id, user_gender_id, item_sales_level, item_collected_level, shop_review_num_level\n",
    "\n",
    "##### 负向特征\n",
    "\n",
    "> item_price_level,\n",
    "item_id,item_brand_id,item_pv_level,user_age_level,\n",
    "user_occupation_id,user_star_level,context_page_id,\n",
    "shop_review_positive_rate,shop_star_level,\n",
    "shop_score_service,shop_score_description,day,hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:696: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(478138, 71)\n"
     ]
    }
   ],
   "source": [
    "# 计算前一天的交易率set到下一天，第0天用回自己\n",
    "# %run ../util/time_utils.py\n",
    "\n",
    "# setTradeRateByDate(raw_df, ['item_city_id', 'item_id', 'item_brand_id', 'shop_id', 'user_id'])\n",
    "\n",
    "# 计算前一天的交易率set到下一天，第0天用回自己\n",
    "%run ../util/trade_info.py\n",
    "\n",
    "# trade_rela = ['item_city_id', 'shop_id', 'user_gender_id', 'item_sales_level', 'item_collected_level', 'shop_review_num_level']\n",
    "trade_rela = ['item_city_id', 'item_id', 'item_brand_id', 'shop_id', 'user_id']\n",
    "\n",
    "# colSm = {}\n",
    "# for col in trade_rela:\n",
    "#     colSm[col] = [15*(mean0) , 15]\n",
    "generateTradeRateByDate(raw_df, trade_rela, 7, None, verbose=False, glbSmoothing=200, glbMean0=0.05)\n",
    "print(raw_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 复合类型拆解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_icl_map ... \n",
      "get_ipl_map ... \n",
      "processing predict_category_property ...\n",
      "processing item_property_list ...\n",
      "processing item_category_list ...\n",
      "generating item_category_1, item_category_2 ...\n"
     ]
    }
   ],
   "source": [
    "%run ../util/complex_type.py\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "le = preprocessing.LabelEncoder()\n",
    "raw_df = process_complex_types(raw_df, get_icl_map(raw_df), get_ipl_map(raw_df))\n",
    "\n",
    "raw_df['item_category_1'] = le.fit_transform(raw_df.item_category_1)\n",
    "raw_df['item_category_2'] = le.fit_transform(raw_df.item_category_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../util/complex_type.py\n",
    "\n",
    "cnt_user_item_review = raw_df[[\"user_id\", \"item_id\", \"instance_id\"]].groupby([\"user_id\", \"item_id\"])['instance_id'].count().to_dict() \n",
    "cnt_user_cate_review = raw_df[[\"user_id\", \"item_category_1\", \"instance_id\"]].groupby([\"user_id\", \"item_category_1\"])['instance_id'].count().to_dict()  \n",
    "\n",
    "f1 = set_review_cnt(\"user_id\", \"item_id\", cnt_user_item_review)\n",
    "f2 = set_review_cnt(\"user_id\", \"item_category_1\", cnt_user_cate_review)\n",
    "\n",
    "tmp = raw_df.sort_values(by=\"context_timestamp\")\n",
    "tmp[\"item_review_cnt\"] = tmp[[\"user_id\", \"item_id\"]].apply(f1, axis=1)\n",
    "tmp[\"cate_review_cnt\"] = tmp[[\"user_id\", \"item_category_1\"]].apply(f2, axis=1)\n",
    "raw_df = tmp.sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 生成矩阵数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420717, 1) (420717, 64) (420717,) (57421, 64) (57421,)\n"
     ]
    }
   ],
   "source": [
    "train_df = raw_df[raw_df['data_set'] == 'training']\n",
    "test_df = raw_df[raw_df['data_set'] == 'testing']\n",
    "\n",
    "non_feat_columns = ['data_set', 'context_timestamp', 'instance_id', 'is_trade', 'context_id',\n",
    "                   'item_property_list', 'item_category_list', 'date', 'predict_category_property',\n",
    "                    'predict_richness', 'predict_category_property', 'item_property_richness', 'item_property_list', \n",
    "                    'item_category_list', 'item_category_1', 'item_category_2'\n",
    "                   ]\n",
    "\n",
    "D = train_df[['date']]\n",
    "X_train = train_df.drop(non_feat_columns, axis=1)\n",
    "y_train = train_df[['is_trade']].values.ravel()\n",
    "X_test = test_df.drop(non_feat_columns, axis=1)\n",
    "# y_test is already exists\n",
    "\n",
    "# X_online = test_df.drop(non_feat_columns, axis=1).values\n",
    "print(D.shape, X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08170, b: 0.08063\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost\n",
    "\n",
    "#import lightgbm as lgb\n",
    "\n",
    "%run ../util/time_series_split.py\n",
    "\n",
    "# clf = lgb.LGBMClassifier(n_jobs=20)\n",
    "clf = xgboost.XGBClassifier(n_jobs=7,max_depth=5,n_estimators=91,min_child_weight=5, max_delta_step=0.9,gamma=6.6)\n",
    "# clf = xgboost.XGBClassifier(n_jobs=7, max_depth=3, n_estimators=230)\n",
    "\n",
    "m = None\n",
    "\n",
    "# 如果移动到线上集, 则输出模型\n",
    "if sum(y_test == -1) > 0:\n",
    "    m = clf.fit(X_train, y_train)\n",
    "    result = pd.DataFrame()\n",
    "    result['instance_id'] = test_df['instance_id']\n",
    "    result['predicted_score'] = pd.DataFrame(m.predict_proba(X_test))[1].values\n",
    "    result.to_csv('submits/7_7452_8095_a8170_b8063.csv', sep = ' ', header=True, index = False)\n",
    "else:\n",
    "    # 分离a,b榜\n",
    "    X_val_a, X_val_b, y_val_a, y_val_b = train_test_split(X_test, y_test, test_size=0.7, shuffle=True, random_state=6)\n",
    "    m = clf.fit(X_train, y_train)\n",
    "    \n",
    "    val_a_loss = log_loss(y_val_a, m.predict_proba(X_val_a))\n",
    "    val_b_loss = log_loss(y_val_b, m.predict_proba(X_val_b))\n",
    "    print('(%s -> %s) train logloss: %.5f, test logloss: %.5f, a: %.5f, b: %.5f' % \\\n",
    "          (starts, ends, \\\n",
    "           log_loss(y_train, m.predict_proba(X_train)), \\\n",
    "           log_loss(y_test, m.predict_proba(X_test)),\\\n",
    "          val_a_loss, val_b_loss))\n",
    "    \n",
    "# ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07348, test logloss: 0.08093, a: 0.08162, b: 0.08064\n",
    "# ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07379, test logloss: 0.08092, a: 0.08160, b: 0.08063\n",
    "# ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07424, test logloss: 0.08098, a: 0.08179, b: 0.08064\n",
    "# ([0, 1, 2, 3, 4, 5] -> [6]) gamma6.6 train logloss: 0.07416, test logloss: 0.08097, a: 0.08177, b: 0.08063\n",
    "# ([0, 1, 2, 3, 4, 5] -> [6]) +max_delta_step 0.9 train logloss: 0.07452, test logloss: 0.08095, a: 0.08170, b: 0.08063"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08475, b: 0.07932\n",
      "1 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07702, b: 0.08264\n",
      "2 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08397, b: 0.07966\n",
      "3 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08060, b: 0.08110\n",
      "4 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07776, b: 0.08232\n",
      "5 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08443, b: 0.07946\n",
      "6 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08170, b: 0.08063\n",
      "7 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08504, b: 0.07920\n",
      "8 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07795, b: 0.08224\n",
      "9 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08523, b: 0.07912\n",
      "10 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08549, b: 0.07901\n",
      "11 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07749, b: 0.08243\n",
      "12 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07785, b: 0.08228\n",
      "13 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07547, b: 0.08330\n",
      "14 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08486, b: 0.07927\n",
      "15 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07501, b: 0.08350\n",
      "16 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08001, b: 0.08135\n",
      "17 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07822, b: 0.08212\n",
      "18 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08412, b: 0.07959\n",
      "19 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08379, b: 0.07974\n",
      "20 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08389, b: 0.07969\n",
      "21 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08298, b: 0.08008\n",
      "22 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08082, b: 0.08101\n",
      "23 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08049, b: 0.08115\n",
      "24 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08392, b: 0.07968\n",
      "25 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07893, b: 0.08182\n",
      "26 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08204, b: 0.08048\n",
      "27 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08027, b: 0.08125\n",
      "28 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08282, b: 0.08015\n",
      "29 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08403, b: 0.07963\n",
      "30 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08270, b: 0.08020\n",
      "31 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07893, b: 0.08182\n",
      "32 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07784, b: 0.08228\n",
      "33 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08288, b: 0.08012\n",
      "34 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08127, b: 0.08082\n",
      "35 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07476, b: 0.08360\n",
      "36 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07770, b: 0.08234\n",
      "37 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08253, b: 0.08027\n",
      "38 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07748, b: 0.08244\n",
      "39 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08329, b: 0.07995\n",
      "40 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07705, b: 0.08262\n",
      "41 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07868, b: 0.08193\n",
      "42 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08348, b: 0.07987\n",
      "43 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07733, b: 0.08250\n",
      "44 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08293, b: 0.08010\n",
      "45 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07987, b: 0.08141\n",
      "46 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07974, b: 0.08147\n",
      "47 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08036, b: 0.08120\n",
      "48 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07704, b: 0.08263\n",
      "49 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08095, b: 0.08095\n",
      "50 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08213, b: 0.08044\n",
      "51 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07919, b: 0.08170\n",
      "52 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08204, b: 0.08048\n",
      "53 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08142, b: 0.08075\n",
      "54 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08201, b: 0.08050\n",
      "55 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08328, b: 0.07995\n",
      "56 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07763, b: 0.08237\n",
      "57 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08464, b: 0.07937\n",
      "58 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08055, b: 0.08112\n",
      "59 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07817, b: 0.08214\n",
      "60 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07958, b: 0.08154\n",
      "61 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07930, b: 0.08166\n",
      "62 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08134, b: 0.08078\n",
      "63 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08372, b: 0.07976\n",
      "64 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07884, b: 0.08186\n",
      "65 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08288, b: 0.08012\n",
      "66 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07575, b: 0.08318\n",
      "67 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08116, b: 0.08086\n",
      "68 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08286, b: 0.08013\n",
      "69 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08142, b: 0.08075\n",
      "70 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08182, b: 0.08058\n",
      "71 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08151, b: 0.08071\n",
      "72 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08182, b: 0.08058\n",
      "73 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07872, b: 0.08191\n",
      "74 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08318, b: 0.08000\n",
      "75 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08354, b: 0.07984\n",
      "76 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08382, b: 0.07972\n",
      "77 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08087, b: 0.08098\n",
      "78 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07784, b: 0.08228\n",
      "79 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08309, b: 0.08004\n",
      "80 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07955, b: 0.08155\n",
      "81 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07869, b: 0.08192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08020, b: 0.08127\n",
      "83 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08394, b: 0.07967\n",
      "84 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08006, b: 0.08133\n",
      "85 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08000, b: 0.08136\n",
      "86 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07662, b: 0.08281\n",
      "87 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08495, b: 0.07924\n",
      "88 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08401, b: 0.07964\n",
      "89 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07765, b: 0.08237\n",
      "90 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08069, b: 0.08106\n",
      "91 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07730, b: 0.08252\n",
      "92 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07882, b: 0.08187\n",
      "93 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08110, b: 0.08089\n",
      "94 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07906, b: 0.08176\n",
      "95 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08118, b: 0.08085\n",
      "96 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08105, b: 0.08091\n",
      "97 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08163, b: 0.08066\n",
      "98 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08215, b: 0.08044\n",
      "99 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08045, b: 0.08117\n",
      "100 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07566, b: 0.08322\n",
      "101 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08109, b: 0.08089\n",
      "102 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07946, b: 0.08159\n",
      "103 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07998, b: 0.08137\n",
      "104 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08122, b: 0.08083\n",
      "105 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08354, b: 0.07984\n",
      "106 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08289, b: 0.08012\n",
      "107 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08151, b: 0.08071\n",
      "108 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07791, b: 0.08225\n",
      "109 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07749, b: 0.08243\n",
      "110 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07970, b: 0.08149\n",
      "111 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07670, b: 0.08277\n",
      "112 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07612, b: 0.08302\n",
      "113 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07769, b: 0.08235\n",
      "114 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07986, b: 0.08142\n",
      "115 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08274, b: 0.08019\n",
      "116 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08871, b: 0.07763\n",
      "117 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08351, b: 0.07985\n",
      "118 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07768, b: 0.08235\n",
      "119 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08317, b: 0.08000\n",
      "120 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08004, b: 0.08134\n",
      "121 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08099, b: 0.08094\n",
      "122 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07873, b: 0.08190\n",
      "123 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08023, b: 0.08126\n",
      "124 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08209, b: 0.08046\n",
      "125 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08068, b: 0.08107\n",
      "126 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08523, b: 0.07912\n",
      "127 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07803, b: 0.08220\n",
      "128 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07872, b: 0.08191\n",
      "129 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07698, b: 0.08265\n",
      "130 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07959, b: 0.08153\n",
      "131 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08639, b: 0.07862\n",
      "132 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08783, b: 0.07800\n",
      "133 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08689, b: 0.07841\n",
      "134 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08110, b: 0.08089\n",
      "135 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07635, b: 0.08292\n",
      "136 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07821, b: 0.08213\n",
      "137 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07875, b: 0.08189\n",
      "138 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08097, b: 0.08094\n",
      "139 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08378, b: 0.07974\n",
      "140 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08230, b: 0.08037\n",
      "141 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08129, b: 0.08081\n",
      "142 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08025, b: 0.08125\n",
      "143 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08118, b: 0.08085\n",
      "144 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08038, b: 0.08120\n",
      "145 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08669, b: 0.07849\n",
      "146 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07588, b: 0.08313\n",
      "147 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07850, b: 0.08200\n",
      "148 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08109, b: 0.08089\n",
      "149 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08278, b: 0.08017\n",
      "150 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08441, b: 0.07947\n",
      "151 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08177, b: 0.08060\n",
      "152 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08579, b: 0.07888\n",
      "153 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07929, b: 0.08166\n",
      "154 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07686, b: 0.08271\n",
      "155 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07912, b: 0.08174\n",
      "156 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08029, b: 0.08123\n",
      "157 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08656, b: 0.07855\n",
      "158 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08524, b: 0.07911\n",
      "159 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08117, b: 0.08086\n",
      "160 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08026, b: 0.08125\n",
      "161 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08399, b: 0.07965\n",
      "162 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08329, b: 0.07995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07568, b: 0.08321\n",
      "164 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08408, b: 0.07961\n",
      "165 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08106, b: 0.08091\n",
      "166 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07937, b: 0.08163\n",
      "167 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08242, b: 0.08032\n",
      "168 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08195, b: 0.08052\n",
      "169 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08108, b: 0.08090\n",
      "170 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07943, b: 0.08160\n",
      "171 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08385, b: 0.07971\n",
      "172 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08393, b: 0.07967\n",
      "173 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08469, b: 0.07935\n",
      "174 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08195, b: 0.08052\n",
      "175 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08574, b: 0.07890\n",
      "176 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07765, b: 0.08237\n",
      "177 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08303, b: 0.08006\n",
      "178 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07907, b: 0.08176\n",
      "179 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08002, b: 0.08135\n",
      "180 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08176, b: 0.08061\n",
      "181 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08324, b: 0.07997\n",
      "182 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08266, b: 0.08022\n",
      "183 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07947, b: 0.08159\n",
      "184 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08322, b: 0.07998\n",
      "185 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08503, b: 0.07920\n",
      "186 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07564, b: 0.08323\n",
      "187 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07879, b: 0.08188\n",
      "188 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08107, b: 0.08090\n",
      "189 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08837, b: 0.07777\n",
      "190 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07928, b: 0.08167\n",
      "191 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07838, b: 0.08205\n",
      "192 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08332, b: 0.07994\n",
      "193 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08247, b: 0.08030\n",
      "194 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08262, b: 0.08024\n",
      "195 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08388, b: 0.07970\n",
      "196 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08172, b: 0.08062\n",
      "197 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07736, b: 0.08249\n",
      "198 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07574, b: 0.08319\n",
      "199 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07911, b: 0.08174\n",
      "200 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08183, b: 0.08058\n",
      "201 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07881, b: 0.08187\n",
      "202 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07818, b: 0.08214\n",
      "203 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08179, b: 0.08059\n",
      "204 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08293, b: 0.08010\n",
      "205 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08317, b: 0.08000\n",
      "206 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08076, b: 0.08103\n",
      "207 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08624, b: 0.07868\n",
      "208 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08615, b: 0.07872\n",
      "209 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07883, b: 0.08186\n",
      "210 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08310, b: 0.08003\n",
      "211 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08232, b: 0.08036\n",
      "212 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08023, b: 0.08126\n",
      "213 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08372, b: 0.07976\n",
      "214 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07600, b: 0.08307\n",
      "215 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07798, b: 0.08222\n",
      "216 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08466, b: 0.07936\n",
      "217 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08581, b: 0.07887\n",
      "218 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08211, b: 0.08045\n",
      "219 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07965, b: 0.08151\n",
      "220 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07936, b: 0.08163\n",
      "221 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07893, b: 0.08182\n",
      "222 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08196, b: 0.08052\n",
      "223 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07588, b: 0.08313\n",
      "224 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08020, b: 0.08127\n",
      "225 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07920, b: 0.08170\n",
      "226 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07705, b: 0.08262\n",
      "227 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08010, b: 0.08131\n",
      "228 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08014, b: 0.08130\n",
      "229 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07648, b: 0.08287\n",
      "230 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08376, b: 0.07975\n",
      "231 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08277, b: 0.08017\n",
      "232 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08094, b: 0.08096\n",
      "233 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08331, b: 0.07994\n",
      "234 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08570, b: 0.07891\n",
      "235 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08335, b: 0.07992\n",
      "236 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08299, b: 0.08008\n",
      "237 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07787, b: 0.08227\n",
      "238 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08910, b: 0.07746\n",
      "239 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08582, b: 0.07887\n",
      "240 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07875, b: 0.08190\n",
      "241 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08378, b: 0.07974\n",
      "242 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08548, b: 0.07901\n",
      "243 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08137, b: 0.08077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08145, b: 0.08074\n",
      "245 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07747, b: 0.08244\n",
      "246 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08259, b: 0.08025\n",
      "247 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07923, b: 0.08169\n",
      "248 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07838, b: 0.08205\n",
      "249 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08616, b: 0.07872\n",
      "250 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08089, b: 0.08098\n",
      "251 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08033, b: 0.08122\n",
      "252 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08304, b: 0.08006\n",
      "253 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07815, b: 0.08215\n",
      "254 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07912, b: 0.08174\n",
      "255 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08210, b: 0.08046\n",
      "256 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07819, b: 0.08214\n",
      "257 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08389, b: 0.07969\n",
      "258 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08031, b: 0.08123\n",
      "259 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08159, b: 0.08068\n",
      "260 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08553, b: 0.07899\n",
      "261 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08146, b: 0.08073\n",
      "262 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08026, b: 0.08125\n",
      "263 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07526, b: 0.08339\n",
      "264 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07443, b: 0.08375\n",
      "265 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08301, b: 0.08007\n",
      "266 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07945, b: 0.08160\n",
      "267 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07746, b: 0.08245\n",
      "268 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08388, b: 0.07969\n",
      "269 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07812, b: 0.08216\n",
      "270 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07508, b: 0.08347\n",
      "271 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07388, b: 0.08398\n",
      "272 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07990, b: 0.08140\n",
      "273 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08142, b: 0.08075\n",
      "274 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08328, b: 0.07995\n",
      "275 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08160, b: 0.08068\n",
      "276 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08239, b: 0.08034\n",
      "277 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07554, b: 0.08327\n",
      "278 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07767, b: 0.08236\n",
      "279 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08594, b: 0.07881\n",
      "280 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08210, b: 0.08046\n",
      "281 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08286, b: 0.08013\n",
      "282 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08175, b: 0.08061\n",
      "283 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08023, b: 0.08126\n",
      "284 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07728, b: 0.08252\n",
      "285 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08165, b: 0.08065\n",
      "286 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08258, b: 0.08025\n",
      "287 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08296, b: 0.08009\n",
      "288 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07653, b: 0.08284\n",
      "289 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07705, b: 0.08262\n",
      "290 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07866, b: 0.08193\n",
      "291 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07990, b: 0.08140\n",
      "292 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08030, b: 0.08123\n",
      "293 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08221, b: 0.08041\n",
      "294 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07908, b: 0.08175\n",
      "295 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08345, b: 0.07988\n",
      "296 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08188, b: 0.08055\n",
      "297 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07538, b: 0.08334\n",
      "298 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08505, b: 0.07919\n",
      "299 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07686, b: 0.08270\n",
      "300 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08013, b: 0.08130\n",
      "301 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08070, b: 0.08106\n",
      "302 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08422, b: 0.07955\n",
      "303 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08237, b: 0.08034\n",
      "304 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08151, b: 0.08071\n",
      "305 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08122, b: 0.08083\n",
      "306 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08547, b: 0.07901\n",
      "307 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08005, b: 0.08134\n",
      "308 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08560, b: 0.07896\n",
      "309 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07755, b: 0.08241\n",
      "310 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07833, b: 0.08207\n",
      "311 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07640, b: 0.08290\n",
      "312 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07513, b: 0.08345\n",
      "313 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08035, b: 0.08121\n",
      "314 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07915, b: 0.08172\n",
      "315 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07975, b: 0.08147\n",
      "316 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07485, b: 0.08356\n",
      "317 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08564, b: 0.07894\n",
      "318 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08893, b: 0.07753\n",
      "319 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07921, b: 0.08170\n",
      "320 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08550, b: 0.07900\n",
      "321 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08265, b: 0.08022\n",
      "322 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07815, b: 0.08215\n",
      "323 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07891, b: 0.08182\n",
      "324 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08224, b: 0.08040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07686, b: 0.08270\n",
      "326 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08376, b: 0.07975\n",
      "327 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08287, b: 0.08013\n",
      "328 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07962, b: 0.08152\n",
      "329 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08137, b: 0.08077\n",
      "330 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07936, b: 0.08163\n",
      "331 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08232, b: 0.08036\n",
      "332 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.08200, b: 0.08050\n",
      "333 ([0, 1, 2, 3, 4, 5] -> [6]) train logloss: 0.07452, test logloss: 0.08095, a: 0.07927, b: 0.08167\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-94edcf3e2cea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mval_a_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mval_b_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%d (%s -> %s) train logloss: %.5f, test logloss: %.5f, a: %.5f, b: %.5f'\u001b[0m \u001b[1;33m%\u001b[0m           \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstarts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mends\u001b[0m\u001b[1;33m,\u001b[0m            \u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m            \u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m          \u001b[0mval_a_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_b_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\xgboost-0.7-py3.6.egg\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, data, output_margin, ntree_limit)\u001b[0m\n\u001b[0;32m    570\u001b[0m             \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0mof\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mexample\u001b[0m \u001b[0mbeing\u001b[0m \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgiven\u001b[0m \u001b[1;32mclass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \"\"\"\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mtest_dmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m         class_probs = self.get_booster().predict(test_dmatrix,\n\u001b[0;32m    574\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\xgboost-0.7-py3.6.egg\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[0;32m    276\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_npy2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\xgboost-0.7-py3.6.egg\\xgboost\\core.py\u001b[0m in \u001b[0;36m_init_from_npy2d\u001b[1;34m(self, mat, missing, nthread)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_float\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m                 nthread))\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    # 分离a,b榜\n",
    "    X_val_a, X_val_b, y_val_a, y_val_b = train_test_split(X_test, y_test, test_size=0.7, shuffle=True, random_state=i)\n",
    "    \n",
    "    val_a_loss = log_loss(y_val_a, m.predict_proba(X_val_a))\n",
    "    val_b_loss = log_loss(y_val_b, m.predict_proba(X_val_b))\n",
    "    print('%d (%s -> %s) train logloss: %.5f, test logloss: %.5f, a: %.5f, b: %.5f' % \\\n",
    "          (i, starts, ends, \\\n",
    "           log_loss(y_train, m.predict_proba(X_train)), \\\n",
    "           log_loss(y_test, m.predict_proba(X_test)),\\\n",
    "          val_a_loss, val_b_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 超参搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "# 训练模型\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost\n",
    "\n",
    "params={\n",
    "    'max_depth': [5],#[6,10,15,20], # 5 is good but takes too long in kaggle env\n",
    "    'subsample': [1],#[1,0.9,0.8,0.7],#[0.1,0.2,0.3,0.4,0.5,0.55,0.6,0.65,0.7,0.8,0.9],#[0.9]\n",
    "    'colsample_bytree': [1],#[0.1,0.2,0.3,0.4,0.5,0.6,0.65,0.7,0.75,0.8,0.9,0.95],#[0.9],\n",
    "    'colsample_bylevel':[1],#[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "    'scale_pos_weight':[1],#[0.7,0.8,1,1.1,1.2],#0.1,0.5,1,2,5\n",
    "    'max_delta_step':[0.9],#[0,0.1,0.001,0.05,0.005,0.5,1,2],\n",
    "    'n_estimators': [91],#[100,90,91,92,93,94,95,96,97,98,99],#[200,230,260,270,280,290,300]\n",
    "    'reg_lambda': [1],#[1.3,1.4,1.5,1.6],\n",
    "    'reg_alpha': [0],#[0,0.01,0.1,0.02,0.2],#[0.01,0.05,0.005,0.2,0.1,0.02,0.0001,0],#\n",
    "    'min_child_weight':[5],#[7,8,9,10,11,12,13,14,15,16,17,18,19,20],#[23],#[20,21,22,23,24,25,26],#\n",
    "    'gamma':[6.6],#[6],#[0.1],#\n",
    "    'learning_rate':[0.1],#[0.01,0.015,0.02,0.025,0.05,0.005,0.1],#[0.02]#\n",
    "}\n",
    "\n",
    "# if sum(y_test == -1) == 0:\n",
    "#     xgb = xgboost.XGBClassifier(n_jobs=7)\n",
    "#     best_score = 1 \n",
    "#     for g in ParameterGrid(params):\n",
    "#         xgb.set_params(**g)\n",
    "\n",
    "#         # 分离a,b榜\n",
    "#         X_val_a, X_val_b, y_val_a, y_val_b = train_test_split(X_test, y_test, test_size=0.7, shuffle=True, random_state=6)\n",
    "#         m = xgb.fit(X_train, y_train, eval_metric='logloss')\n",
    "\n",
    "#         val_train_loss = log_loss(y_train, m.predict_proba(X_train))\n",
    "#         val_test_loss = log_loss(y_test, m.predict_proba(X_test))\n",
    "#         val_a_loss = log_loss(y_val_a, m.predict_proba(X_val_a))\n",
    "#         val_b_loss = log_loss(y_val_b, m.predict_proba(X_val_b))\n",
    "#         print('-'*80)\n",
    "#         print(g)\n",
    "#         print('(%s -> %s) train logloss: %.5f, test logloss: %.5f, a: %.5f, b: %.5f' % \\\n",
    "#               (starts, ends, val_train_loss, val_test_loss, val_a_loss, val_b_loss))\n",
    "\n",
    "#         # save if best\n",
    "#         if val_test_loss < best_score:\n",
    "#             best_score = val_test_loss\n",
    "#             best_grid = g\n",
    "\n",
    "#     print('-'*80, '\\n')        \n",
    "#     print (\"log loss: %0.5f\" % best_score )\n",
    "#     print (\"Grid:\", best_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-03 08:28:22.683362\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
