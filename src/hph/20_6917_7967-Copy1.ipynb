{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加上两个用户行为特征\n",
    "\n",
    "1. lb8699基础上\n",
    "2. 添加他的新特征\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "%run ../util/base_frame.py\n",
    "\n",
    "train_df = pd.read_table('../../round1_ijcai_18_train_20180301.txt',sep=' ')\n",
    "#test_df = pd.read_table('../../round1_ijcai_18_test_a_20180301.txt',sep=' ')\n",
    "test_df = pd.read_table('../../round1_ijcai_18_test_b_20180418.txt',sep=' ')\n",
    "\n",
    "fa = BaseFrame(train_df, test_df, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 先处理时序数据, 基本标签化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(521026, 34)\n"
     ]
    }
   ],
   "source": [
    "# 时间处理: 分离天, 星期几, 上中下午/晚上, 小时数\n",
    "# date最终不使用，直接用day(第 0 - 7 天)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "fa.df['weekday'] = fa.df['context_timestamp'].apply(lambda x: datetime.fromtimestamp(x).weekday())\n",
    "fa.df['hour'] = fa.df['context_timestamp'].apply(lambda x: datetime.fromtimestamp(x).hour)\n",
    "fa.df['minute'] = fa.df['context_timestamp'].apply(lambda x: datetime.fromtimestamp(x).minute)\n",
    "fa.df['seconds'] = fa.df['context_timestamp'].apply(lambda x: datetime.fromtimestamp(x).second)\n",
    "print(fa.df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标签化\n",
    "from sklearn import preprocessing\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "\n",
    "for col in ['item_id', 'item_brand_id', 'item_city_id', 'shop_id', 'user_id']:\n",
    "    fa.df[col] = lbl.fit_transform(fa.df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 特征处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 时间交易频次特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(521026, 48)\n"
     ]
    }
   ],
   "source": [
    "def groupbySizeFeat(df, feats, name):\n",
    "    target = df.groupby(feats).size().reset_index().rename(columns={0: name})\n",
    "    return pd.merge(df, target, 'left', on=feats)\n",
    "\n",
    "fa.df = groupbySizeFeat(fa.df, ['user_id', 'day'], 'user_query_day')\n",
    "fa.df = groupbySizeFeat(fa.df, ['user_id', 'weekday'], 'user_query_weekday')\n",
    "fa.df = groupbySizeFeat(fa.df, ['user_id', 'day', 'hour'], 'user_query_day_hour')\n",
    "fa.df = groupbySizeFeat(fa.df, ['day', 'user_id', 'item_id'], 'day_user_item_id')\n",
    "fa.df = groupbySizeFeat(fa.df, ['day', 'hour', 'minute', 'user_id', 'item_id'], 'day_hour_minute_user_item_id')\n",
    "fa.df = groupbySizeFeat(fa.df, ['day', 'hour', 'item_id'], 'number_day_hour_item_id')\n",
    "fa.df = groupbySizeFeat(fa.df, ['item_id', 'user_id'], 'item_user_id')\n",
    "fa.df = groupbySizeFeat(fa.df, ['item_category_list', 'item_city_id'], 'item_category_city_id')\n",
    "fa.df = groupbySizeFeat(fa.df, ['item_category_list', 'item_sales_level'], 'item_category_sales_level')\n",
    "fa.df = groupbySizeFeat(fa.df, ['item_category_list', 'item_price_level'], 'item_category_price_level')\n",
    "\n",
    "fa.df = groupbySizeFeat(fa.df, ['item_id', 'item_sales_level'], 'item_ID_sales_level')\n",
    "fa.df = groupbySizeFeat(fa.df, ['item_id', 'item_collected_level'], 'item_ID_collected_level')\n",
    "fa.df = groupbySizeFeat(fa.df, ['user_id'], 'number_user_id')\n",
    "fa.df = groupbySizeFeat(fa.df, ['shop_id'], 'number_shop_id')\n",
    "print(fa.df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类目特征OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    fa.df['predict_category_property' + str(i)] = lbl.fit_transform(fa.df['predict_category_property'].map(\n",
    "        lambda x: str(str(x).split(';')[i]) if len(str(x).split(';')) > i else ''))\n",
    "\n",
    "for i in range(1, 3):\n",
    "    fa.df['item_category_list' + str(i)] = lbl.fit_transform(fa.df['item_category_list'].map(\n",
    "        lambda x: str(str(x).split(';')[i]) if len(str(x).split(';')) > i else ''))  # item_category\n",
    "\n",
    "for i in range(10):\n",
    "    fa.df['item_property_list' + str(i)] = lbl.fit_transform(fa.df['item_property_list'].map(\n",
    "        lambda x: str(str(x).split(';')[i]) if len(str(x).split(';')) > i else ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa.df['gender0'] = fa.df['user_gender_id'].apply(lambda x: x + 1 if x == -1 else x)\n",
    "fa.df['age0'] = fa.df['user_age_level'].apply(lambda x: 1003 if x == -1  else x)\n",
    "fa.df['occupation0'] = fa.df['user_occupation_id'].apply(lambda x: 2005 if x == -1  else x)\n",
    "fa.df['star0'] = fa.df['user_star_level'].apply(lambda x: 3006 if x == -1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa.df = groupbySizeFeat(fa.df, ['item_brand_id', 'shop_review_positive_rate'], 'number_item_brand_positive_rate')\n",
    "fa.df = groupbySizeFeat(fa.df, ['item_brand_id', 'shop_star_level'], 'number_item_brand_shop_star')\n",
    "fa.df = groupbySizeFeat(fa.df, ['item_city_id', 'item_pv_level'], 'number_item_city_pv_level')\n",
    "fa.df = groupbySizeFeat(fa.df, ['item_city_id', 'user_id'], 'number_item_city_user_id')\n",
    "fa.df = groupbySizeFeat(fa.df, ['item_price_level', 'item_sales_level'], 'number_item_price_sales_level')\n",
    "fa.df = groupbySizeFeat(fa.df, ['predict_category_property', 'item_sales_level'], 'number_predict_category_sales_level')\n",
    "fa.df = groupbySizeFeat(fa.df, ['item_collected_level', 'shop_id'], 'number_collected_shop_id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 访问频次\n",
    ">比如说user_id, shop_id group: user访问shop的第几次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(521026, 79)\n"
     ]
    }
   ],
   "source": [
    "%run ../util/time_utils.py\n",
    "\n",
    "\n",
    "fa.df['last_1_user_shop'] = getLastImpressTime(fa.df, ['user_id', 'shop_id'])\n",
    "fa.df['last_1_user_item'] = getLastImpressTime(fa.df, ['user_id', 'item_id'])\n",
    "fa.df['last_1_user_shop_item'] = getLastImpressTime(fa.df, ['user_id', 'shop_id', 'item_id'])\n",
    "print(fa.df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../util/time_utils.py\n",
    "\n",
    "fa.df['next_1_user_shop'] = getNextImpressTime(fa.df, ['user_id', 'shop_id'])\n",
    "fa.df['next_1_user_item'] = getNextImpressTime(fa.df, ['user_id', 'item_id'])\n",
    "fa.df['next_1_user_shop_item'] = getNextImpressTime(fa.df, ['user_id', 'shop_id', 'item_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重复列特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(521026, 96)\n"
     ]
    }
   ],
   "source": [
    "%run ../util/time_utils.py\n",
    "dup_feat = ['item_id', 'user_id']\n",
    "fa.df = generateColDupByDay(fa.df, dup_feat, list(range(1, 8)), verbose=False)\n",
    "print(fa.df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交易率特征选择\n",
    "\n",
    "*固定smooth为10*\n",
    "\n",
    "1. 特征是否独立提升?\n",
    "2. 平滑是否不会改变正负向?\n",
    "\n",
    "##### 正向特征\n",
    "\n",
    "> item_city_id, shop_id, user_gender_id, item_sales_level, item_collected_level, shop_review_num_level\n",
    "\n",
    "##### 负向特征\n",
    "\n",
    "> item_price_level,\n",
    "item_id,item_brand_id,item_pv_level,user_age_level,\n",
    "user_occupation_id,user_star_level,context_page_id,\n",
    "shop_review_positive_rate,shop_star_level,\n",
    "shop_score_service,shop_score_description,day,hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:696: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(521026, 105)\n"
     ]
    }
   ],
   "source": [
    "# 计算前一天的交易率set到下一天，第0天用回自己\n",
    "%run ../util/trade_info.py\n",
    "\n",
    "trade_rela = ['item_id', 'item_brand_id', 'shop_id', 'user_id']\n",
    "\n",
    "generateTradeRateByDate(fa.df, trade_rela, 7, None, verbose=False, glbSmoothing=200, glbMean0=0.05)\n",
    "print(fa.df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 复合交易率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['instance_id', 'item_id', 'item_category_list', 'item_property_list',\n",
       "       'item_brand_id', 'item_city_id', 'item_price_level', 'item_sales_level',\n",
       "       'item_collected_level', 'item_pv_level',\n",
       "       ...\n",
       "       'user_id_dup_gg_7', '_key1', 'exp_d_item_id_7', 'cnt_d_item_id_7',\n",
       "       'exp_d_item_brand_id_7', 'cnt_d_item_brand_id_7', 'exp_d_shop_id_7',\n",
       "       'cnt_d_shop_id_7', 'exp_d_user_id_7', 'cnt_d_user_id_7'],\n",
       "      dtype='object', length=105)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa.df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data before day 0 is setted, with period 7, data size 78268\n",
      "data before day 1 is setted, with period 7, data size 70931\n",
      "data before day 2 is setted, with period 7, data size 68387\n",
      "data before day 3 is setted, with period 7, data size 71199\n",
      "data before day 4 is setted, with period 7, data size 68318\n",
      "data before day 5 is setted, with period 7, data size 63614\n",
      "data before day 6 is setted, with period 7, data size 57421\n",
      "data before day 7 is setted, with period 7, data size 42888\n",
      "data before day 0 is setted, with period 7, data size 78268\n",
      "data before day 1 is setted, with period 7, data size 70931\n",
      "data before day 2 is setted, with period 7, data size 68387\n",
      "data before day 3 is setted, with period 7, data size 71199\n",
      "data before day 4 is setted, with period 7, data size 68318\n",
      "data before day 5 is setted, with period 7, data size 63614\n",
      "data before day 6 is setted, with period 7, data size 57421\n",
      "data before day 7 is setted, with period 7, data size 42888\n",
      "data before day 0 is setted, with period 7, data size 78268\n",
      "data before day 1 is setted, with period 7, data size 70931\n",
      "data before day 2 is setted, with period 7, data size 68387\n",
      "data before day 3 is setted, with period 7, data size 71199\n",
      "data before day 4 is setted, with period 7, data size 68318\n",
      "data before day 5 is setted, with period 7, data size 63614\n",
      "data before day 6 is setted, with period 7, data size 57421\n",
      "data before day 7 is setted, with period 7, data size 42888\n",
      "data before day 0 is setted, with period 7, data size 78268\n",
      "data before day 1 is setted, with period 7, data size 70931\n",
      "data before day 2 is setted, with period 7, data size 68387\n",
      "data before day 3 is setted, with period 7, data size 71199\n",
      "data before day 4 is setted, with period 7, data size 68318\n",
      "data before day 5 is setted, with period 7, data size 63614\n",
      "data before day 6 is setted, with period 7, data size 57421\n",
      "data before day 7 is setted, with period 7, data size 42888\n",
      "data before day 0 is setted, with period 7, data size 78268\n",
      "data before day 1 is setted, with period 7, data size 70931\n",
      "data before day 2 is setted, with period 7, data size 68387\n",
      "data before day 3 is setted, with period 7, data size 71199\n",
      "data before day 4 is setted, with period 7, data size 68318\n",
      "data before day 5 is setted, with period 7, data size 63614\n",
      "data before day 6 is setted, with period 7, data size 57421\n",
      "data before day 7 is setted, with period 7, data size 42888\n",
      "data before day 0 is setted, with period 7, data size 78268\n",
      "data before day 1 is setted, with period 7, data size 70931\n",
      "data before day 2 is setted, with period 7, data size 68387\n",
      "data before day 3 is setted, with period 7, data size 71199\n",
      "data before day 4 is setted, with period 7, data size 68318\n",
      "data before day 5 is setted, with period 7, data size 63614\n",
      "data before day 6 is setted, with period 7, data size 57421\n",
      "data before day 7 is setted, with period 7, data size 42888\n",
      "(521026, 123)\n"
     ]
    }
   ],
   "source": [
    "%run  ../util/trade_info.py\n",
    "\n",
    "\n",
    "fa.df['u2i_sz'], fa.df['u2i_sum'], fa.df['u2i_rate'] = getMultiTradeRate(fa.df, ['user_id', 'item_id'])\n",
    "fa.df['u2shop_sz'], fa.df['u2shop_sum'], fa.df['u2shop_rate'] = getMultiTradeRate(fa.df, ['user_id', 'shop_id'])\n",
    "fa.df['u2brand_sz'], fa.df['u2brand_sum'], fa.df['u2brand_rate'] = getMultiTradeRate(fa.df, ['user_id', 'item_brand_id'])\n",
    "fa.df['u2page_sz'], fa.df['u2page_sum'], fa.df['u2page_rate'] = getMultiTradeRate(fa.df, ['user_id', 'context_page_id'])\n",
    "fa.df['u2hour_sz'], fa.df['u2hour_sum'], fa.df['u2hour_rate'] = getMultiTradeRate(fa.df, ['user_id', 'hour'])\n",
    "fa.df['u2sstar_sz'], fa.df['u2sstar_sum'], fa.df['u2sstar_rate'] = getMultiTradeRate(fa.df, ['user_id', 'shop_star_level'])\n",
    "print(fa.df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 复合类型拆解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['instance_id', 'item_id', 'item_category_list',\n",
       "       'item_property_list', 'item_brand_id', 'item_city_id',\n",
       "       'item_price_level', 'item_sales_level', 'item_collected_level',\n",
       "       'item_pv_level', 'user_id', 'user_gender_id', 'user_age_level',\n",
       "       'user_occupation_id', 'user_star_level', 'context_id',\n",
       "       'context_timestamp', 'context_page_id',\n",
       "       'predict_category_property', 'shop_id', 'shop_review_num_level',\n",
       "       'shop_review_positive_rate', 'shop_star_level',\n",
       "       'shop_score_service', 'shop_score_delivery',\n",
       "       'shop_score_description', 'is_trade', 'date', 'day', 'data_set',\n",
       "       'weekday', 'hour', 'minute', 'seconds', 'user_query_day',\n",
       "       'user_query_weekday', 'user_query_day_hour', 'day_user_item_id',\n",
       "       'day_hour_minute_user_item_id', 'number_day_hour_item_id',\n",
       "       'item_user_id', 'item_category_city_id',\n",
       "       'item_category_sales_level', 'item_category_price_level',\n",
       "       'item_ID_sales_level', 'item_ID_collected_level', 'number_user_id',\n",
       "       'number_shop_id', 'predict_category_property0',\n",
       "       'predict_category_property1', 'predict_category_property2',\n",
       "       'predict_category_property3', 'predict_category_property4',\n",
       "       'item_category_list1', 'item_category_list2',\n",
       "       'item_property_list0', 'item_property_list1',\n",
       "       'item_property_list2', 'item_property_list3',\n",
       "       'item_property_list4', 'item_property_list5',\n",
       "       'item_property_list6', 'item_property_list7',\n",
       "       'item_property_list8', 'item_property_list9', 'gender0', 'age0',\n",
       "       'occupation0', 'star0', 'number_item_brand_positive_rate',\n",
       "       'number_item_brand_shop_star', 'number_item_city_pv_level',\n",
       "       'number_item_city_user_id', 'number_item_price_sales_level',\n",
       "       'number_predict_category_sales_level', 'number_collected_shop_id',\n",
       "       'last_1_user_shop', 'last_1_user_item', 'last_1_user_shop_item',\n",
       "       'next_1_user_shop', 'next_1_user_item', 'next_1_user_shop_item',\n",
       "       'item_id_dup_gg_1', 'item_id_dup_gg_2', 'item_id_dup_gg_3',\n",
       "       'item_id_dup_gg_4', 'item_id_dup_gg_5', 'item_id_dup_gg_6',\n",
       "       'item_id_dup_gg_7', 'user_id_dup_gg_1', 'user_id_dup_gg_2',\n",
       "       'user_id_dup_gg_3', 'user_id_dup_gg_4', 'user_id_dup_gg_5',\n",
       "       'user_id_dup_gg_6', 'user_id_dup_gg_7', '_key1', 'exp_d_item_id_7',\n",
       "       'cnt_d_item_id_7', 'exp_d_item_brand_id_7',\n",
       "       'cnt_d_item_brand_id_7', 'exp_d_shop_id_7', 'cnt_d_shop_id_7',\n",
       "       'exp_d_user_id_7', 'cnt_d_user_id_7', 'u2i_sz', 'u2i_sum',\n",
       "       'u2i_rate', 'u2shop_sz', 'u2shop_sum', 'u2shop_rate', 'u2brand_sz',\n",
       "       'u2brand_sum', 'u2brand_rate', 'u2page_sz', 'u2page_sum',\n",
       "       'u2page_rate', 'u2hour_sz', 'u2hour_sum', 'u2hour_rate',\n",
       "       'u2sstar_sz', 'u2sstar_sum', 'u2sstar_rate'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa.df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_icl_map ... \n",
      "get_ipl_map ... \n",
      "processing predict_category_property ...\n",
      "processing item_property_list ...\n",
      "processing item_category_list ...\n",
      "generating item_category_1, item_category_2 ...\n",
      "(521026, 132)\n"
     ]
    }
   ],
   "source": [
    "%run ../util/complex_type.py\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "le = preprocessing.LabelEncoder()\n",
    "fa.df = process_complex_types_v2(fa.df, get_icl_map(fa.df), get_ipl_map(fa.df))\n",
    "\n",
    "fa.df['item_category_1'] = le.fit_transform(fa.df.item_category_1)\n",
    "fa.df['item_category_2'] = le.fit_transform(fa.df.item_category_2)\n",
    "print(fa.df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fa.df['context_timestamp'] = fa.df.context_timestamp_x\n",
    "# del fa.df['context_timestamp_y']\n",
    "# del fa.df['context_timestamp_x']\n",
    "#del fa.df['context_timestamp_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(521026, 134)\n"
     ]
    }
   ],
   "source": [
    "%run ../util/complex_type.py\n",
    "\n",
    "cnt_user_item_review = fa.df[[\"user_id\", \"item_id\", \"instance_id\"]].groupby([\"user_id\", \"item_id\"])['instance_id'].count().to_dict() \n",
    "cnt_user_cate_review = fa.df[[\"user_id\", \"item_category_1\", \"instance_id\"]].groupby([\"user_id\", \"item_category_1\"])['instance_id'].count().to_dict()  \n",
    "\n",
    "f1 = set_review_cnt(\"user_id\", \"item_id\", cnt_user_item_review)\n",
    "f2 = set_review_cnt(\"user_id\", \"item_category_1\", cnt_user_cate_review)\n",
    "\n",
    "tmp = fa.df.sort_values(by=\"context_timestamp\")\n",
    "tmp[\"item_review_cnt\"] = tmp[[\"user_id\", \"item_id\"]].apply(f1, axis=1)\n",
    "tmp[\"cate_review_cnt\"] = tmp[[\"user_id\", \"item_category_1\"]].apply(f2, axis=1)\n",
    "fa.df = tmp.sort_index()\n",
    "\n",
    "print(fa.df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(521026, 134) (42888,)\n"
     ]
    }
   ],
   "source": [
    "print(fa.df.shape, fa.y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 fitXgb训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "## 刷新base_frame(debug)\n",
    "# %run ../util/base_frame.py\n",
    "\n",
    "# tmp = fa.df\n",
    "# fa = BaseFrame(train_df, test_df, 7)\n",
    "# fa.df = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (478138, 121), y_train (478138,), X_test (42888, 121), y_test (42888,)\n",
      "> (478138, 121) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "#import lightgbm as lgb\n",
    "%run ../util/base_frame.py\n",
    "\n",
    "\n",
    "\n",
    "non_feat_columns = ['context_timestamp', 'instance_id', 'is_trade', 'context_id',\n",
    "                   'item_property_list', 'item_category_list',  'predict_category_property','tmp'\n",
    "                   ]\n",
    "\n",
    "# cnt_d_shop_id 单特征变差，全集变好\n",
    "neg_feat_columns = ['exp_d_user_id_7', 'cnt_d_item_id_7', 'cnt_d_item_brand_id_7']\n",
    "\n",
    "\n",
    "\n",
    "params = {\n",
    "    'max_depth':[3],\n",
    "    'n_estimators':[3000],\n",
    "    'min_child_weight':[5],\n",
    "    'gamma':[5]\n",
    "}\n",
    "\n",
    "\n",
    "m = None\n",
    "if sum(fa.y_test == -1) == 0:\n",
    "    # 进入测试阶段\n",
    "    xgb = xgboost.XGBClassifier(n_jobs=7)\n",
    "    for g in ParameterGrid(params):\n",
    "        xgb.set_params(**g)\n",
    "        print('>', '- '*40, '\\n\\n> ', g, '\\n')\n",
    "#         fa.fit(xgb, pos_feat_columns, '11', drop=False)\n",
    "        fa.fit(xgb, non_feat_columns+neg_feat_columns, '14', drop=True, early_stopping_rounds=150)\n",
    "        print(xgb.best_score)\n",
    "        # fa.fit(xgb, non_feat_columns+['exp_d_user_id', 'cnt_d_item_brand_id'], '11', drop=True)\n",
    "else:\n",
    "    # 进入提交阶段\n",
    "    xgb = xgboost.XGBClassifier(**{'gamma': 5, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 227, 'n_jobs': 7})\n",
    "    fa.fit(xgb, non_feat_columns+neg_feat_columns, '20_6917_7967', drop=True, early_stopping_rounds=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12,18))\n",
    "xgboost.plot_importance(xgb, ax=ax, importance_type='cover')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
